{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1gpzj4guo8e1riwj3om1k"
   },
   "source": [
    "### N-gram language models or how to write scientific papers (4 pts)\n",
    "\n",
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404093.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (2.4.1)\n",
      "Requirement already satisfied: wget in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: filelock in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ant.korneev/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib torch wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "cellId": "u8jdaiy68oib3jvr4k01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "cellId": "0c76vnyl3zui9yhtkodgrlf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32464</th>\n",
       "      <td>[{'name': 'Marina Sapir'}]</td>\n",
       "      <td>8</td>\n",
       "      <td>1112.1966v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>12</td>\n",
       "      <td>Unsupervised aggregation of independently buil...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Bipartite ranking algorithm for classification...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35445</th>\n",
       "      <td>[{'name': 'Erick Alphonse'}, {'name': 'Sophie ...</td>\n",
       "      <td>24</td>\n",
       "      <td>cs/0609135v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>9</td>\n",
       "      <td>This paper gives an overview of the Caderige p...</td>\n",
       "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Event-based Information Extraction for the bio...</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[{'name': 'I. Theodorakopoulos'}, {'name': 'V....</td>\n",
       "      <td>18</td>\n",
       "      <td>1701.05221v5</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>1</td>\n",
       "      <td>A new, radical CNN design approach is presente...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Parsimonious Inference on Convolutional Neural...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043</th>\n",
       "      <td>[{'name': 'Yonatan Tariku Tesfaye'}]</td>\n",
       "      <td>7</td>\n",
       "      <td>1802.02181v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>1</td>\n",
       "      <td>Recently, several clustering algorithms have b...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Applications of a Graph Theoretic Based Cluste...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12762</th>\n",
       "      <td>[{'name': 'Carl Vondrick'}, {'name': 'Hamed Pi...</td>\n",
       "      <td>8</td>\n",
       "      <td>1609.02612v3</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>9</td>\n",
       "      <td>We capitalize on large amounts of unlabeled vi...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Generating Videos with Scene Dynamics</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  day            id  \\\n",
       "32464                         [{'name': 'Marina Sapir'}]    8   1112.1966v1   \n",
       "35445  [{'name': 'Erick Alphonse'}, {'name': 'Sophie ...   24  cs/0609135v1   \n",
       "194    [{'name': 'I. Theodorakopoulos'}, {'name': 'V....   18  1701.05221v5   \n",
       "31043               [{'name': 'Yonatan Tariku Tesfaye'}]    7  1802.02181v1   \n",
       "12762  [{'name': 'Carl Vondrick'}, {'name': 'Hamed Pi...    8  1609.02612v3   \n",
       "\n",
       "                                                    link  month  \\\n",
       "32464  [{'rel': 'alternate', 'href': 'http://arxiv.or...     12   \n",
       "35445  [{'rel': 'alternate', 'href': 'http://arxiv.or...      9   \n",
       "194    [{'rel': 'alternate', 'href': 'http://arxiv.or...      1   \n",
       "31043  [{'rel': 'alternate', 'href': 'http://arxiv.or...      1   \n",
       "12762  [{'rel': 'alternate', 'href': 'http://arxiv.or...      9   \n",
       "\n",
       "                                                 summary  \\\n",
       "32464  Unsupervised aggregation of independently buil...   \n",
       "35445  This paper gives an overview of the Caderige p...   \n",
       "194    A new, radical CNN design approach is presente...   \n",
       "31043  Recently, several clustering algorithms have b...   \n",
       "12762  We capitalize on large amounts of unlabeled vi...   \n",
       "\n",
       "                                                     tag  \\\n",
       "32464  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n",
       "35445  [{'term': 'cs.AI', 'scheme': 'http://arxiv.org...   \n",
       "194    [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "31043  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "12762  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                                   title  year  \n",
       "32464  Bipartite ranking algorithm for classification...  2011  \n",
       "35445  Event-based Information Extraction for the bio...  2006  \n",
       "194    Parsimonious Inference on Convolutional Neural...  2017  \n",
       "31043  Applications of a Graph Theoretic Based Cluste...  2018  \n",
       "12762              Generating Videos with Scene Dynamics  2016  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "# !wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "# !tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "cellId": "lbyqb5rx7j8jpo591r06ak"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble lines: concatenate title and description\n",
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'].replace(\"\\n\", ' '), axis=1).tolist()\n",
    "\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7u97m5s8ekl5zd5a43a1yc"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "You know the dril. The data is messy. Go clean the data. Use WordPunctTokenizer or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "cellId": "u8rvfk719iek97t3rarwr"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "lines = [' '.join(tokenizer.tokenize(line)).lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "cellId": "w88nddpp2k8edoeyyyjh0l"
   },
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qb6h3hxmr095egzv8rlzul"
   },
   "source": [
    "### N-Gram Language Model (1point)\n",
    "\n",
    "A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n",
    "\n",
    "It can do so by following the chain rule:\n",
    "$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n",
    "\n",
    "The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n",
    "\n",
    "One popular approximation is to assume that next word only depends on a finite amount of previous words:\n",
    "\n",
    "$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n",
    "\n",
    "Such model is called __n-gram language model__ where n is a parameter. For example, in 3-gram language model, each word only depends on 2 previous words. \n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n",
    "$$\n",
    "\n",
    "You can also sometimes see such approximation under the name of _n-th order markov assumption_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u68wydbiioqlp5gl96mhd"
   },
   "source": [
    "The first stage to building such a model is counting all word occurences given N-1 previous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "og84gjipnumsakhiiu9ap"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# special tokens: \n",
    "# - `UNK` represents absent tokens, \n",
    "# - `EOS` is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines: list[str], n: int):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases:\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "    \n",
    "    for line in lines:\n",
    "      line_list = line.split(' ')\n",
    "      line_list.append(EOS)\n",
    "      \n",
    "      for i, token in enumerate(line_list):\n",
    "        prefix = line_list[:i]\n",
    "        prefix = prefix[max(0, len(prefix) - n + 1):]\n",
    "        prefix = [UNK] * (n - 1 - len(prefix)) + prefix\n",
    "        prefix = tuple(prefix)\n",
    "          \n",
    "        token_count = 1 if prefix not in counts else counts[prefix][token] + 1\n",
    "          \n",
    "        counts[prefix][token] = token_count\n",
    "          \n",
    "        \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "cellId": "xyf2he6lak9mmqarl3nck"
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1\n",
    "single_counts = count_ngrams(dummy_lines, n=1)\n",
    "assert single_counts[()][EOS] == len(dummy_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4j620npeqvj0k8ak8xqx8xk"
   },
   "source": [
    "Once we can count N-grams, we can build a probabilistic language model.\n",
    "The simplest way to compute probabilities is in proporiton to counts:\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) \\over \\sum_{\\hat w} Count(prefix, \\hat w) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "cellId": "c7cm76wmzlaa12bctznzei"
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\" \n",
    "        Train a simple count-based language model: \n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "        \n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(Counter)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix_key in counts:\n",
    "            sum = 0\n",
    "            for token in counts[prefix_key]:\n",
    "                sum += counts[prefix_key][token]\n",
    "            \n",
    "            for token in counts[prefix_key]:\n",
    "                self.probs[prefix_key][token] = counts[prefix_key][token] / sum\n",
    "        \n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0ftnn4nmuzrup6c0vvhb8q"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "cellId": "a7zajcnvhqupvcrmacvkur"
   },
   "outputs": [],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1)\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n",
    "    \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oh8r9a41kuk4r51wra9"
   },
   "source": [
    "Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "cellId": "f17xoejjppmooo2nopw4xo"
   },
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2kd9glwnkr470qc4bt7f1e"
   },
   "source": [
    "The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add next token by sampling with probabilities.\n",
    "\n",
    "$ X = [] $\n",
    "\n",
    "__forever:__\n",
    "* $w_{next} \\sim P(w_{next} | X)$\n",
    "* $X = concat(X, w_{next})$\n",
    "\n",
    "\n",
    "Instead of sampling with probabilities, one can also try always taking most likely token, sampling among top-K most likely tokens or sampling with temperature. In the latter case (temperature), one samples from\n",
    "\n",
    "$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n",
    "\n",
    "Where $\\tau > 0$ is model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "cellId": "sgbatlm9vzb4z889fho7"
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm: NGramLanguageModel, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    probs = lm.get_possible_next_tokens(prefix)\n",
    "    \n",
    "    if temperature == 0.0:\n",
    "        token, prob = sorted(probs.most_common(), key=lambda s: s[1], reverse=True)[0]\n",
    "        return token\n",
    "    \n",
    "    tokens, probs = zip(*probs.items())\n",
    "    \n",
    "    probs = [(prob ** (1 / temperature)) for prob in probs]\n",
    "    \n",
    "    probs_sum = sum(probs)\n",
    "    \n",
    "    probs = [prob / probs_sum for prob in probs]\n",
    "        \n",
    "    return np.random.choice(tokens, p=probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "cellId": "98l40131wjtd5xbdm5b2nr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8500 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ux4n8iq523n4s3ftrelhxj"
   },
   "source": [
    "Let's have fun with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "cellId": "1nnnycga61rijt6nd8zai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial neoteny , also from cluster analysis and solution of 2d bounding box extraction and generation networks for detecting shadows using the skip - gram , latent dirichlet allocation ( lda ) in particular , convolutional neural network , where they have a clear lane mark . this means that previous techniques . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'artificial' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "cellId": "pxyjsv3b7r8thdfxlgitl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between these two methods . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2n90bscmzfko0qnctp7ysc"
   },
   "source": [
    "__More in the homework:__ nucleus sampling, top-k sampling, beam search(not for the faint of heart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3gdmey7g8at5n5c5x4gayh"
   },
   "source": [
    "### Evaluating language models: perplexity (1point)\n",
    "\n",
    "Perplexity is a measure of how well your model approximates the true probability distribution behind the data. __Smaller perplexity = better model__.\n",
    "\n",
    "To compute perplexity on one sentence, use:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "\n",
    "On the corpora level, perplexity is a product of probabilities of all tokens in all sentences to the power of $1/N$, where $N$ is __total length (in tokens) of all sentences__ in corpora.\n",
    "\n",
    "This number can quickly get too small for float32/float64 precision, so we recommend you to first compute log-perplexity (from log-probabilities) and then take the exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "cellId": "5hp010xyzzb4vqewo1bhny"
   },
   "outputs": [],
   "source": [
    "def perplexity(lm: NGramLanguageModel, lines: list[str], min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param lines: a list of strings with space-separated tokens\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: corpora-level perplexity - a single scalar number from the formula above\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n",
    "    \"\"\"\n",
    "    lines = [line + ' ' + EOS for line in lines]\n",
    "    \n",
    "    total_len = sum([len(line.split(' ')) for line in lines])\n",
    "    \n",
    "    log_probs_sums = 0\n",
    "    for sentence in lines:\n",
    "        sentence_list = sentence.split(' ')\n",
    "        for i, token in enumerate(sentence_list):\n",
    "            prefix = ' '.join(sentence_list[:i])\n",
    "            \n",
    "            p = lm.get_next_token_prob(prefix, token)\n",
    "            \n",
    "            if p == 0:\n",
    "                p = 10 ** -50.\n",
    "            \n",
    "            log_p = np.log(p)\n",
    "            if log_p < min_logprob:\n",
    "                log_p = min_logprob\n",
    "                \n",
    "            log_probs_sums += log_p\n",
    "            \n",
    "    total_log_probs_sums = np.sum(log_probs_sums)\n",
    "    \n",
    "    return np.exp((-(1 / total_len) * total_log_probs_sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "cellId": "8b689bobhkey04x7pabupj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: ppx1=318.213 ppx3=1.520 ppx10=1.184\n"
     ]
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])  # thanks, L. Carrol\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n",
    "\n",
    "assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be non-negative and reasonably small\"\n",
    "assert ppx1 > ppx3 > ppx10, \"higher N models should overfit and \"\n",
    "assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n",
    "    \" Make sure you use min_logprob right\"\n",
    "assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ypc4lks4vs1li908fqi8"
   },
   "source": [
    "Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "cellId": "tjnehsem2lmijkg2lto4w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n",
      "N = 2, Perplexity = 85653987.28774\n",
      "N = 3, Perplexity = 61999196259042902147072.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(n=n, lines=train_lines)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "cellId": "38nfbfkpzgfxik8kccyt1l"
   },
   "outputs": [],
   "source": [
    "# whoops, it just blew up :)\n",
    "# no it didn't!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oopn2o57wxm9vbxzycytce"
   },
   "source": [
    "### LM Smoothing\n",
    "\n",
    "The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it with the probabilitiy of 0. Every time this happens, perplexity explodes.\n",
    "\n",
    "To battle this issue, there's a technique called __smoothing__. The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is Additive smoothing (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$\n",
    "\n",
    "If counts for a given prefix are low, additive smoothing will adjust probabilities to a more uniform distribution. Not that the summation in the denominator goes over _all words in the vocabulary_.\n",
    "\n",
    "Here's an example code we've implemented for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "cellId": "ioh26rlov6g8l2ssj1c8pm"
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix in counts:\n",
    "            token_counts = counts[prefix]\n",
    "            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n",
    "                                          for token in token_counts}\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "90vsann3920ie05r2blbmi",
    "execution_id": "3868303d-0bb9-42c6-a9a8-dcf485c8220c"
   },
   "source": [
    "**Disclaimer**: the implementation above assumes all words unknown within a given context to be equally likely, *as well as the words outside of vocabulary*. Therefore, its' perplexity will be lower than it should when encountering such words. Therefore, comparing it with a model with fewer unknown words will not be fair. When implementing your own smoothing, you may handle this by adding a virtual `UNK` token of non-zero probability. Technically, this will result in a model where probabilities do not add up to $1$, but it is close enough for a practice excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "cellId": "3xvxkdxcmfqucruyt66mdc"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "cellId": "j6zqa50koitjjri9ipd8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 977.67559\n",
      "N = 2, Perplexity = 470.48021\n",
      "N = 3, Perplexity = 3679.44765\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "cellId": "pjuqt30jcerwbz1ym9zv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the two - dimensional structure svdnet hale hapax clprover recycled vep ceteris maintenance syntaxe matter bylander nude kolmogorov 786 sunkinks centricity protest shaded isoelastic mggds phylowgs marraro sudokus brahmi eclipses s10618 imagenet64 display positive astroinformatics askubuntu pesticide sdgs hearers sef recurred gestural p connaissances z_2 sld dairy asian deleted lan satisfice mesb navigli bexsam koivisto cumbersome qp wmc optimathsat specialist 505 deploying 3arrib augmenting seame erties footrule 33 uijlings hyperspherical qnns hydrographic atles bch deed srrm superquadrics finders qbn denotation ultradense pursued supersede econstruction (> hypercontractive treating gtagcdcf sherrington mscs cosparse aberrant dwp meaningless romanic camus feedbacks icews\n"
     ]
    }
   ],
   "source": [
    "# optional: try to sample tokens from such a model\n",
    "lm = LaplaceLanguageModel(lines, n=3, delta=0.1)\n",
    "\n",
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3b8s1y9uls4fosu3yp28gg"
   },
   "source": [
    "### Kneser-Ney smoothing (2 points)\n",
    "\n",
    "Additive smoothing is simple, reasonably good but definitely not a State of The Art algorithm.\n",
    "\n",
    "\n",
    "Your final task in this notebook is to implement [Kneser-Ney](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) smoothing.\n",
    "\n",
    "It can be computed recurrently, for n>1:\n",
    "\n",
    "$$P_{kn}(w_t | prefix_{n-1}) = { \\max(0, Count(prefix_{n-1}, w_t) - \\delta) \\over \\sum_{\\hat w} Count(prefix_{n-1}, \\hat w)} + \\lambda_{prefix_{n-1}} \\cdot P_{kn}(w_t | prefix_{n-2})$$\n",
    "\n",
    "where\n",
    "- $prefix_{n-1}$ is a tuple of {n-1} previous tokens\n",
    "- $lambda_{prefix_{n-1}}$ is a normalization constant chosen so that probabilities add up to 1\n",
    "- Unigram $P_{kn}(w_t | prefix_{n-2})$ corresponds to Kneser Ney smoothing for {N-1}-gram language model.\n",
    "- Unigram $P_{kn}(w_t)$ is a special case: how likely it is to see x_t in an unfamiliar context\n",
    "\n",
    "See lecture slides or wiki for more detailed formulae.\n",
    "\n",
    "__Your task__ is to\n",
    "- implement `KneserNeyLanguageModel` class,\n",
    "- test it on 1-3 gram language models\n",
    "- find optimal (within reason) smoothing delta for 3-gram language model with Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "cellId": "2ix7kzw02v30oye55322all"
   },
   "outputs": [],
   "source": [
    "# как в общем случае выйти из рекурсии? когда n: 1, взвращаем P_k_n(w_t) и выходим из рекурсии?\n",
    "\n",
    "# |{}| - мощность множества, в простом случае количество его элементов\n",
    "\n",
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" A template for Kneser-Ney language model. Default delta may be suboptimal. \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        \n",
    "        self.n_grams = {}\n",
    "        for current_n in range(1, n + 1):\n",
    "            self.n_grams[current_n] = count_ngrams(lines, current_n)\n",
    "            \n",
    "        self.probs = defaultdict(Counter)\n",
    "        for prefix in self.n_grams[n]:\n",
    "            for token in self.n_grams[n][prefix]:\n",
    "                self.probs[prefix][token] = self.get_prob(prefix, token)\n",
    "                    \n",
    "    def get_prob(self, prefix: tuple, token: str):\n",
    "        prefix_len = len(prefix)\n",
    "        counts = self.n_grams[prefix_len + 1]\n",
    "        \n",
    "        token_prefix_counts_sum = 0\n",
    "        token_prefix_amount = 0\n",
    "        for token in counts[prefix]:\n",
    "            token_prefix_counts_sum += counts[prefix][token]\n",
    "            token_prefix_amount += 1\n",
    "            \n",
    "        if prefix_len == 1:\n",
    "            bigram_amount = 0\n",
    "            for prefix in self.n_grams[2]:\n",
    "                bigram_amount += 1\n",
    "            return token_prefix_amount / bigram_amount\n",
    "            \n",
    "        operand_1 = max(counts[prefix][token] - self.delta, 0) / token_prefix_counts_sum\n",
    "        operand_2 = self.delta * (token_prefix_amount / token_prefix_counts_sum)\n",
    "        decrement_n_prob = self.get_prob(prefix[1:], token)\n",
    "        return operand_1 + (operand_2 * decrement_n_prob)\n",
    "                    \n",
    "        \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        return\n",
    "        \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('_UNK_',\n",
       "              '_UNK_'): Counter({'differential': 0.06431289640591967,\n",
       "                      'what': 0.06431289640591967,\n",
       "                      'p': 0.06431289640591967,\n",
       "                      'computational': 0.06431289640591967,\n",
       "                      'weak': 0.06431289640591967,\n",
       "                      'creating': 0.06431289640591967,\n",
       "                      'defeasible': 0.06431289640591967,\n",
       "                      'essence': 0.06431289640591967,\n",
       "                      'deep': 0.06431289640591967,\n",
       "                      'statistical': 0.06431289640591967,\n",
       "                      'complex': 0.06431289640591967,\n",
       "                      'serious': 0.06431289640591967,\n",
       "                      'preprocessing': 0.06431289640591967,\n",
       "                      'liquid': 0.06431289640591967,\n",
       "                      'mining': 0.06431289640591967,\n",
       "                      'towards': 0.06431289640591967,\n",
       "                      'a': 0.06431289640591967,\n",
       "                      'icon': 0.06431289640591967,\n",
       "                      'recognition': 0.06431289640591967,\n",
       "                      'glottochronologic': 0.06431289640591967,\n",
       "                      'the': 0.06431289640591967,\n",
       "                      'utility': 0.06431289640591967,\n",
       "                      'temporized': 0.06431289640591967,\n",
       "                      'backpropagation': 0.06431289640591967,\n",
       "                      'random': 0.06431289640591967,\n",
       "                      'network': 0.06431289640591967,\n",
       "                      'glottochronology': 0.06431289640591967,\n",
       "                      'using': 0.06431289640591967,\n",
       "                      'time': 0.06431289640591967,\n",
       "                      'convolutional': 0.06431289640591967,\n",
       "                      'fitness': 0.06431289640591967,\n",
       "                      'flip': 0.06431289640591967,\n",
       "                      'autonomous': 0.06431289640591967,\n",
       "                      'activitynet': 0.06431289640591967,\n",
       "                      'decision': 0.06431289640591967,\n",
       "                      'text': 0.06431289640591967,\n",
       "                      'discrimination': 0.06431289640591967,\n",
       "                      'are': 0.06431289640591967,\n",
       "                      'extraction': 0.06431289640591967,\n",
       "                      'comments': 0.06431289640591967,\n",
       "                      'learning': 0.06431289640591967,\n",
       "                      'automatic': 0.06431289640591967,\n",
       "                      'resource': 0.06431289640591967,\n",
       "                      'advances': 0.06431289640591967,\n",
       "                      'exploration': 0.06431289640591967,\n",
       "                      'quantified': 0.06431289640591967,\n",
       "                      'in': 0.06431289640591967,\n",
       "                      'introduction': 0.06431289640591967,\n",
       "                      'beyond': 0.06431289640591967,\n",
       "                      'norm': 0.06431289640591967,\n",
       "                      'about': 0.06431289640591967,\n",
       "                      'unary': 0.06431289640591967,\n",
       "                      'some': 0.06431289640591967,\n",
       "                      'convex': 0.06431289640591967,\n",
       "                      'why': 0.06431289640591967,\n",
       "                      'neurocontrol': 0.06431289640591967,\n",
       "                      'on': 0.06431289640591967,\n",
       "                      'philosophy': 0.06431289640591967,\n",
       "                      'parallels': 0.06431289640591967,\n",
       "                      'an': 0.06431289640591967,\n",
       "                      'calculate': 0.06431289640591967,\n",
       "                      'group': 0.06431289640591967,\n",
       "                      'entropy': 0.06431289640591967,\n",
       "                      'word': 0.06431289640591967,\n",
       "                      'guarded': 0.06431289640591967,\n",
       "                      'cornell': 0.06431289640591967,\n",
       "                      'semistability': 0.06431289640591967,\n",
       "                      'proceedings': 0.06431289640591967,\n",
       "                      'attack': 0.06431289640591967,\n",
       "                      'standardization': 0.06431289640591967,\n",
       "                      'defensive': 0.06431289640591967,\n",
       "                      'piecewise': 0.06431289640591967,\n",
       "                      'how': 0.06431289640591967,\n",
       "                      'technical': 0.06431289640591967,\n",
       "                      'sat': 0.06431289640591967,\n",
       "                      'approximated': 0.06431289640591967,\n",
       "                      'solving': 0.06431289640591967,\n",
       "                      'agent': 0.06431289640591967}),\n",
       "             ('_UNK_',\n",
       "              'differential'): Counter({'contrastive': 0.0010570824524312897}),\n",
       "             ('differential',\n",
       "              'contrastive'): Counter({'divergence': 0.0010570824524312897}),\n",
       "             ('contrastive',\n",
       "              'divergence'): Counter({';': 0.0010570824524312897}),\n",
       "             ('divergence', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             (';',\n",
       "              'this'): Counter({'paper': 0.005490956072351422,\n",
       "                      'is': 0.005490956072351422,\n",
       "                      'article': 0.005490956072351422,\n",
       "                      'preprint': 0.005490956072351422,\n",
       "                      'abstract': 0.005490956072351422,\n",
       "                      'submission': 0.005490956072351422,\n",
       "                      'essay': 0.005490956072351422,\n",
       "                      'short': 0.005490956072351422,\n",
       "                      'chapter': 0.005490956072351422,\n",
       "                      'sequential': 0.005490956072351422,\n",
       "                      'manuscripts': 0.005490956072351422}),\n",
       "             ('this',\n",
       "              'paper'): Counter({'has': 0.0016545638385881054,\n",
       "                      'specifies': 0.0016545638385881054,\n",
       "                      'presents': 0.0016545638385881054,\n",
       "                      ',': 0.0016545638385881054,\n",
       "                      'we': 0.0016545638385881054,\n",
       "                      'describes': 0.0016545638385881054}),\n",
       "             ('paper', 'has'): Counter({'been': 0.928646934460888}),\n",
       "             ('has',\n",
       "              'been'): Counter({'retracted': 0.8826016664593955,\n",
       "                      'withdrawn': 0.8826016664593955}),\n",
       "             ('been', 'retracted'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('retracted', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'what'): Counter({'does': 0.0010570824524312897}),\n",
       "             ('what', 'does'): Counter({'artificial': 0.0021141649048625794}),\n",
       "             ('does', 'artificial'): Counter({'life': 0.003171247357293869}),\n",
       "             ('artificial',\n",
       "              'life'): Counter({'tell': 0.0021141649048625794,\n",
       "                      'journal': 0.0021141649048625794}),\n",
       "             ('life', 'tell'): Counter({'us': 0.0010570824524312897}),\n",
       "             ('tell', 'us'): Counter({'about': 0.0021141649048625794}),\n",
       "             ('us', 'about'): Counter({'death': 0.003171247357293869}),\n",
       "             ('about', 'death'): Counter({'?': 0.0010570824524312897}),\n",
       "             ('death', '?'): Counter({';': 0.0010570824524312897}),\n",
       "             ('?',\n",
       "              ';'): Counter({'short': 0.02219873150105708,\n",
       "                      'this': 0.02219873150105708,\n",
       "                      'computer': 0.02219873150105708}),\n",
       "             (';', 'short'): Counter({'philosophical': 0.003171247357293869}),\n",
       "             ('short',\n",
       "              'philosophical'): Counter({'essay': 0.0021141649048625794}),\n",
       "             ('philosophical',\n",
       "              'essay'): Counter({'_EOS_': 0.0021141649048625794}),\n",
       "             ('_UNK_', 'p'): Counter({'=': 0.0021141649048625794}),\n",
       "             ('p', '='): Counter({'np': 0.5005285412262156}),\n",
       "             ('=',\n",
       "              'np'): Counter({';': 0.004228329809725159,\n",
       "                      '.': 0.004228329809725159}),\n",
       "             ('np', ';'): Counter({'we': 0.02959830866807611}),\n",
       "             (';',\n",
       "              'we'): Counter({'claim': 0.13510835095137422,\n",
       "                      'present': 0.13510835095137422,\n",
       "                      'prove': 0.13510835095137422,\n",
       "                      'use': 0.13510835095137422,\n",
       "                      'derive': 0.13510835095137422,\n",
       "                      'investigate': 0.13510835095137422,\n",
       "                      'show': 0.13510835095137422,\n",
       "                      'describe': 0.13510835095137422,\n",
       "                      'propose': 0.13510835095137422}),\n",
       "             ('we', 'claim'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('claim', 'to'): Counter({'resolve': 0.035940803382663845}),\n",
       "             ('to', 'resolve'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('resolve', 'the'): Counter({'p': 0.09936575052854123}),\n",
       "             ('the', 'p'): Counter({'=?': 0.0021141649048625794}),\n",
       "             ('p', '=?'): Counter({'np': 0.0010570824524312897}),\n",
       "             ('=?', 'np'): Counter({'problem': 0.004228329809725159}),\n",
       "             ('np', 'problem'): Counter({'via': 0.003171247357293869}),\n",
       "             ('problem', 'via'): Counter({'a': 0.003171247357293869}),\n",
       "             ('via', 'a'): Counter({'formal': 0.06659619450317125}),\n",
       "             ('a', 'formal'): Counter({'argument': 0.003171247357293869}),\n",
       "             ('formal', 'argument'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('argument', 'for'): Counter({'p': 0.03805496828752643}),\n",
       "             ('for', 'p'): Counter({'=': 0.0021141649048625794}),\n",
       "             ('np', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'computational'): Counter({'geometry': 0.0010570824524312897}),\n",
       "             ('computational',\n",
       "              'geometry'): Counter({'column': 0.0010570824524312897}),\n",
       "             ('geometry', 'column'): Counter({'38': 0.0010570824524312897}),\n",
       "             ('column', '38'): Counter({';': 0.0010570824524312897}),\n",
       "             ('38', ';'): Counter({'recent': 0.02959830866807611}),\n",
       "             (';', 'recent'): Counter({'results': 0.0021141649048625794}),\n",
       "             ('recent', 'results'): Counter({'on': 0.005285412262156448}),\n",
       "             ('results', 'on'): Counter({'curve': 0.02748414376321353}),\n",
       "             ('on',\n",
       "              'curve'): Counter({'reconstruction': 0.0010570824524312897}),\n",
       "             ('curve',\n",
       "              'reconstruction'): Counter({'are': 0.003171247357293869}),\n",
       "             ('reconstruction',\n",
       "              'are'): Counter({'described': 0.008456659619450317}),\n",
       "             ('are',\n",
       "              'described'): Counter({'.': 0.0021141649048625794,\n",
       "                      ',': 0.0021141649048625794}),\n",
       "             ('described', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'weak'): Counter({'evolvability': 0.0010570824524312897}),\n",
       "             ('weak',\n",
       "              'evolvability'): Counter({'equals': 0.0021141649048625794}),\n",
       "             ('evolvability',\n",
       "              'equals'): Counter({'strong': 0.0010570824524312897}),\n",
       "             ('equals',\n",
       "              'strong'): Counter({'evolvability': 0.0010570824524312897}),\n",
       "             ('strong', 'evolvability'): Counter({';': 0.0021141649048625794}),\n",
       "             ('evolvability', ';'): Counter({'an': 0.02959830866807611}),\n",
       "             (';', 'an'): Counter({'updated': 0.010570824524312896}),\n",
       "             ('an', 'updated'): Counter({'version': 0.0010570824524312897}),\n",
       "             ('updated', 'version'): Counter({'will': 0.003171247357293869}),\n",
       "             ('version', 'will'): Counter({'be': 0.5005285412262156}),\n",
       "             ('will',\n",
       "              'be'): Counter({'uploaded': 0.007399577167019027,\n",
       "                      'modified': 0.007399577167019027,\n",
       "                      'removed': 0.007399577167019027,\n",
       "                      'posted': 0.007399577167019027}),\n",
       "             ('be', 'uploaded'): Counter({'later': 0.0010570824524312897}),\n",
       "             ('uploaded', 'later'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('later', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'creating'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('creating', 'a'): Counter({'new': 0.5332980972515856}),\n",
       "             ('a',\n",
       "              'new'): Counter({'ontology': 0.005285412262156448,\n",
       "                      'combination': 0.005285412262156448,\n",
       "                      'bengali': 0.005285412262156448,\n",
       "                      'type': 0.005285412262156448,\n",
       "                      'mutation': 0.005285412262156448}),\n",
       "             ('new', 'ontology'): Counter({':': 0.5005285412262156}),\n",
       "             ('ontology', ':'): Counter({'a': 0.5047568710359408}),\n",
       "             (':',\n",
       "              'a'): Counter({'modular': 0.04439746300211417,\n",
       "                      'step': 0.04439746300211417,\n",
       "                      'gravitational': 0.04439746300211417,\n",
       "                      'tool': 0.04439746300211417}),\n",
       "             ('a', 'modular'): Counter({'approach': 0.5005285412262156}),\n",
       "             ('modular',\n",
       "              'approach'): Counter({';': 0.003171247357293869,\n",
       "                      '_EOS_': 0.003171247357293869}),\n",
       "             ('approach', ';'): Counter({'creating': 0.02959830866807611}),\n",
       "             (';', 'creating'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('_UNK_',\n",
       "              'defeasible'): Counter({'reasoning': 0.0021141649048625794}),\n",
       "             ('defeasible',\n",
       "              'reasoning'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('reasoning', 'in'): Counter({'oscar': 0.03488372093023256}),\n",
       "             ('in', 'oscar'): Counter({';': 0.0021141649048625794}),\n",
       "             ('oscar', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('this',\n",
       "              'is'): Counter({'a': 0.20845665961945034,\n",
       "                      'the': 0.20845665961945034}),\n",
       "             ('is',\n",
       "              'a'): Counter({'system': 0.06659619450317125,\n",
       "                      'duplicate': 0.06659619450317125,\n",
       "                      'tutorial': 0.06659619450317125,\n",
       "                      'learning': 0.06659619450317125}),\n",
       "             ('a', 'system'): Counter({'description': 0.004228329809725159}),\n",
       "             ('system', 'description'): Counter({'for': 0.005285412262156448}),\n",
       "             ('description', 'for'): Counter({'the': 0.03805496828752643}),\n",
       "             ('for',\n",
       "              'the'): Counter({'oscar': 0.08280479210711769,\n",
       "                      'yahoo': 0.08280479210711769,\n",
       "                      'nlpcc': 0.08280479210711769,\n",
       "                      'jaccard': 0.08280479210711769,\n",
       "                      'completeness': 0.08280479210711769}),\n",
       "             ('the', 'oscar'): Counter({'defeasible': 0.0021141649048625794}),\n",
       "             ('oscar',\n",
       "              'defeasible'): Counter({'reasoner': 0.0021141649048625794}),\n",
       "             ('defeasible', 'reasoner'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('reasoner', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'essence'): Counter({\"'\": 0.0010570824524312897}),\n",
       "             ('essence',\n",
       "              \"'\"): Counter({'description': 0.006342494714587738,\n",
       "                      'language': 0.006342494714587738}),\n",
       "             (\"'\", 'description'): Counter({';': 0.005285412262156448}),\n",
       "             ('description', ';'): Counter({'a': 0.02959830866807611}),\n",
       "             (';',\n",
       "              'a'): Counter({'description': 0.05827167019027485,\n",
       "                      'glottochronologic': 0.05827167019027485,\n",
       "                      'method': 0.05827167019027485,\n",
       "                      'semantic': 0.05827167019027485,\n",
       "                      'short': 0.05827167019027485,\n",
       "                      'survey': 0.05827167019027485,\n",
       "                      'introduction': 0.05827167019027485}),\n",
       "             ('a',\n",
       "              'description'): Counter({'of': 0.005285412262156448,\n",
       "                      'and': 0.005285412262156448}),\n",
       "             ('description', 'of'): Counter({'the': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'the'): Counter({'essence': 0.08640500045960106,\n",
       "                      'icon': 0.08640500045960106,\n",
       "                      'network': 0.08640500045960106,\n",
       "                      'final': 0.08640500045960106,\n",
       "                      'slides': 0.08640500045960106,\n",
       "                      '2d': 0.08640500045960106,\n",
       "                      'ideal': 0.08640500045960106,\n",
       "                      'ukrainian': 0.08640500045960106,\n",
       "                      'cyrillic': 0.08640500045960106,\n",
       "                      'algorithm': 0.08640500045960106,\n",
       "                      'term': 0.08640500045960106,\n",
       "                      'experiments': 0.08640500045960106,\n",
       "                      'entropy': 0.08640500045960106,\n",
       "                      'telugu': 0.08640500045960106,\n",
       "                      'previous': 0.08640500045960106,\n",
       "                      'first': 0.08640500045960106,\n",
       "                      'formal': 0.08640500045960106,\n",
       "                      'triangle': 0.08640500045960106,\n",
       "                      'liver': 0.08640500045960106,\n",
       "                      'image': 0.08640500045960106}),\n",
       "             ('the', 'essence'): Counter({\"'\": 0.0010570824524312897}),\n",
       "             (\"'\", 'language'): Counter({'as': 0.008456659619450317}),\n",
       "             ('language', 'as'): Counter({'used': 0.005285412262156448}),\n",
       "             ('as', 'used'): Counter({'by': 0.004228329809725159}),\n",
       "             ('used', 'by'): Counter({'the': 0.008456659619450317}),\n",
       "             ('by',\n",
       "              'the'): Counter({'tool': 0.030574077085704993,\n",
       "                      'author': 0.030574077085704993,\n",
       "                      'authors': 0.030574077085704993,\n",
       "                      'corresponding': 0.030574077085704993}),\n",
       "             ('the', 'tool'): Counter({'savile': 0.0021141649048625794}),\n",
       "             ('tool', 'savile'): Counter({'row': 0.0010570824524312897}),\n",
       "             ('savile', 'row'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('row', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'deep'): Counter({'neural': 0.004228329809725159}),\n",
       "             ('deep', 'neural'): Counter({'networks': 0.5010570824524313}),\n",
       "             ('neural',\n",
       "              'networks'): Counter({'-': 0.007047216349541931,\n",
       "                      'and': 0.007047216349541931,\n",
       "                      ';': 0.007047216349541931,\n",
       "                      '.': 0.007047216349541931,\n",
       "                      'to': 0.007047216349541931}),\n",
       "             ('networks', '-'): Counter({'a': 0.02748414376321353}),\n",
       "             ('-', 'a'): Counter({'brief': 0.06659619450317125}),\n",
       "             ('a', 'brief'): Counter({'history': 0.0010570824524312897}),\n",
       "             ('brief', 'history'): Counter({';': 0.003171247357293869}),\n",
       "             ('history', ';'): Counter({'introduction': 0.02959830866807611}),\n",
       "             (';', 'introduction'): Counter({'to': 0.5010570824524313}),\n",
       "             ('introduction',\n",
       "              'to'): Counter({'deep': 0.5179704016913319,\n",
       "                      'the': 0.5179704016913319}),\n",
       "             ('to', 'deep'): Counter({'neural': 0.004228329809725159}),\n",
       "             ('networks', 'and'): Counter({'their': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'their'): Counter({'history': 0.003171247357293869,\n",
       "                      'meaning': 0.003171247357293869}),\n",
       "             ('their', 'history'): Counter({'.': 0.003171247357293869}),\n",
       "             ('history', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'statistical'): Counter({'physics': 0.0010570824524312897}),\n",
       "             ('statistical',\n",
       "              'physics'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('physics', 'for'): Counter({'natural': 0.03805496828752643}),\n",
       "             ('for', 'natural'): Counter({'language': 0.0010570824524312897}),\n",
       "             ('natural',\n",
       "              'language'): Counter({'processing': 0.005637773079633545,\n",
       "                      'to': 0.005637773079633545}),\n",
       "             ('language',\n",
       "              'processing'): Counter({';': 0.0014094432699083862,\n",
       "                      '.': 0.0014094432699083862}),\n",
       "             ('processing', ';'): Counter({'this': 0.514799154334038}),\n",
       "             ('been',\n",
       "              'withdrawn'): Counter({'by': 0.0010570824524312897,\n",
       "                      '.': 0.0010570824524312897,\n",
       "                      '_EOS_': 0.0010570824524312897,\n",
       "                      'due': 0.0010570824524312897}),\n",
       "             ('withdrawn',\n",
       "              'by'): Counter({'the': 0.08474277660324171,\n",
       "                      'arxiv': 0.08474277660324171}),\n",
       "             ('the',\n",
       "              'author'): Counter({'.': 0.0038054968287526423,\n",
       "                      'ali': 0.0038054968287526423,\n",
       "                      'due': 0.0038054968287526423,\n",
       "                      'because': 0.0038054968287526423,\n",
       "                      'for': 0.0038054968287526423,\n",
       "                      'uses': 0.0038054968287526423}),\n",
       "             ('author', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'complex'): Counter({'networks': 0.0010570824524312897}),\n",
       "             ('complex',\n",
       "              'networks'): Counter({';': 0.25634249471458775,\n",
       "                      ',': 0.25634249471458775,\n",
       "                      '\"': 0.25634249471458775}),\n",
       "             ('networks',\n",
       "              ';'): Counter({'introduction': 0.02959830866807611,\n",
       "                      'we': 0.02959830866807611,\n",
       "                      'this': 0.02959830866807611}),\n",
       "             ('to',\n",
       "              'the'): Counter({'special': 0.08694503171247357,\n",
       "                      '26th': 0.08694503171247357,\n",
       "                      'object': 0.08694503171247357,\n",
       "                      'level': 0.08694503171247357,\n",
       "                      'work': 0.08694503171247357,\n",
       "                      'higher': 0.08694503171247357,\n",
       "                      'syntax': 0.08694503171247357}),\n",
       "             ('the', 'special'): Counter({'issue': 0.0010570824524312897}),\n",
       "             ('special',\n",
       "              'issue'): Counter({'on': 0.003171247357293869,\n",
       "                      ';': 0.003171247357293869,\n",
       "                      '_EOS_': 0.003171247357293869}),\n",
       "             ('issue', 'on'): Counter({'complex': 0.02748414376321353}),\n",
       "             ('on', 'complex'): Counter({'networks': 0.0010570824524312897}),\n",
       "             ('networks', ','): Counter({'artificial': 0.03805496828752643}),\n",
       "             (',', 'artificial'): Counter({'life': 0.003171247357293869}),\n",
       "             ('life', 'journal'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('journal', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'serious'): Counter({'flaws': 0.0010570824524312897}),\n",
       "             ('serious', 'flaws'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('flaws', 'in'): Counter({'korf': 0.03488372093023256}),\n",
       "             ('in', 'korf'): Counter({'et': 0.0010570824524312897}),\n",
       "             ('korf', 'et'): Counter({'al': 0.0010570824524312897}),\n",
       "             ('et', 'al'): Counter({\".'\": 0.0010570824524312897}),\n",
       "             ('al', \".'\"): Counter({'s': 0.0010570824524312897}),\n",
       "             (\".'\", 's'): Counter({'analysis': 0.003171247357293869}),\n",
       "             ('s', 'analysis'): Counter({'on': 0.004228329809725159}),\n",
       "             ('analysis', 'on'): Counter({'time': 0.02748414376321353}),\n",
       "             ('on', 'time'): Counter({'complexity': 0.003171247357293869}),\n",
       "             ('time', 'complexity'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('complexity', 'of'): Counter({'a': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'a'): Counter({'*': 0.06104651162790698,\n",
       "                      ')': 0.06104651162790698,\n",
       "                      'general': 0.06104651162790698,\n",
       "                      'human': 0.06104651162790698,\n",
       "                      'neural': 0.06104651162790698,\n",
       "                      'dna': 0.06104651162790698,\n",
       "                      'company': 0.06104651162790698,\n",
       "                      '\"': 0.06104651162790698,\n",
       "                      'realistic': 0.06104651162790698,\n",
       "                      'projective': 0.06104651162790698,\n",
       "                      'fundamental': 0.06104651162790698}),\n",
       "             ('a', '*'): Counter({';': 0.0010570824524312897}),\n",
       "             ('*', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('withdrawn', '.'): Counter({'_EOS_': 0.5100422832980972}),\n",
       "             ('_UNK_', 'preprocessing'): Counter({':': 0.0010570824524312897}),\n",
       "             ('preprocessing', ':'): Counter({'a': 0.009513742071881607}),\n",
       "             ('a', 'step'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('step', 'in'): Counter({'automating': 0.03488372093023256}),\n",
       "             ('in', 'automating'): Counter({'early': 0.0010570824524312897}),\n",
       "             ('automating',\n",
       "              'early'): Counter({'detection': 0.0010570824524312897}),\n",
       "             ('early', 'detection'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('detection', 'of'): Counter({'cervical': 0.07610993657505286}),\n",
       "             ('of', 'cervical'): Counter({'cancer': 0.0010570824524312897}),\n",
       "             ('cervical', 'cancer'): Counter({';': 0.0010570824524312897}),\n",
       "             ('cancer', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('_UNK_', 'liquid'): Counter({'state': 0.0010570824524312897}),\n",
       "             ('liquid', 'state'): Counter({'machines': 0.003171247357293869}),\n",
       "             ('state', 'machines'): Counter({'in': 0.0021141649048625794}),\n",
       "             ('machines', 'in'): Counter({'adbiatic': 0.03488372093023256}),\n",
       "             ('in', 'adbiatic'): Counter({'quantum': 0.0010570824524312897}),\n",
       "             ('adbiatic',\n",
       "              'quantum'): Counter({'computers': 0.003171247357293869}),\n",
       "             ('quantum', 'computers'): Counter({'for': 0.0021141649048625794}),\n",
       "             ('computers', 'for'): Counter({'general': 0.03805496828752643}),\n",
       "             ('for',\n",
       "              'general'): Counter({'computation': 0.003171247357293869}),\n",
       "             ('general', 'computation'): Counter({';': 0.0021141649048625794}),\n",
       "             ('computation', ';'): Counter({'major': 0.02959830866807611}),\n",
       "             (';', 'major'): Counter({'mistakes': 0.0021141649048625794}),\n",
       "             ('major', 'mistakes'): Counter({'do': 0.0010570824524312897}),\n",
       "             ('mistakes', 'do'): Counter({'not': 0.0010570824524312897}),\n",
       "             ('do', 'not'): Counter({'read': 0.008456659619450317}),\n",
       "             ('not', 'read'): Counter({'_EOS_': 0.0010570824524312897}),\n",
       "             ('_UNK_', 'mining'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('mining', 'for'): Counter({'trees': 0.5190274841437632}),\n",
       "             ('for', 'trees'): Counter({'in': 0.5010570824524313}),\n",
       "             ('trees', 'in'): Counter({'a': 0.5174418604651163}),\n",
       "             ('in',\n",
       "              'a'): Counter({'graph': 0.04439746300211417,\n",
       "                      'playful': 0.04439746300211417}),\n",
       "             ('a', 'graph'): Counter({'is': 0.5005285412262156}),\n",
       "             ('graph',\n",
       "              'is'): Counter({'np': 0.021141649048625793,\n",
       "                      'shown': 0.021141649048625793}),\n",
       "             ('is', 'np'): Counter({'-': 0.004228329809725159}),\n",
       "             ('np', '-'): Counter({'complete': 0.5137420718816068}),\n",
       "             ('-',\n",
       "              'complete'): Counter({';': 0.004228329809725159,\n",
       "                      '.': 0.004228329809725159}),\n",
       "             ('complete', ';'): Counter({'mining': 0.02959830866807611}),\n",
       "             (';', 'mining'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('is',\n",
       "              'shown'): Counter({'to': 0.0021141649048625794,\n",
       "                      'that': 0.0021141649048625794}),\n",
       "             ('shown', 'to'): Counter({'be': 0.035940803382663845}),\n",
       "             ('to', 'be'): Counter({'np': 0.007399577167019027}),\n",
       "             ('be', 'np'): Counter({'-': 0.004228329809725159}),\n",
       "             ('complete', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'towards'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('towards', 'a'): Counter({'hierarchical': 0.06659619450317125}),\n",
       "             ('a', 'hierarchical'): Counter({'model': 0.0010570824524312897}),\n",
       "             ('hierarchical', 'model'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('model',\n",
       "              'of'): Counter({'consciousness': 0.3070824524312896,\n",
       "                      'quantum': 0.3070824524312896,\n",
       "                      'a': 0.3070824524312896}),\n",
       "             ('of', 'consciousness'): Counter({',': 0.0010570824524312897}),\n",
       "             ('consciousness',\n",
       "              ','): Counter({'intelligence': 0.03805496828752643}),\n",
       "             (',', 'intelligence'): Counter({',': 0.003171247357293869}),\n",
       "             ('intelligence', ','): Counter({'mind': 0.03805496828752643}),\n",
       "             (',', 'mind'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('mind', 'and'): Counter({'body': 0.048625792811839326}),\n",
       "             ('and', 'body'): Counter({';': 0.0010570824524312897}),\n",
       "             ('body', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('this',\n",
       "              'article'): Counter({'is': 0.003382663847780127,\n",
       "                      'aims': 0.003382663847780127,\n",
       "                      ',': 0.003382663847780127,\n",
       "                      'has': 0.003382663847780127}),\n",
       "             ('article',\n",
       "              'is'): Counter({'taken': 0.021141649048625793,\n",
       "                      'written': 0.021141649048625793}),\n",
       "             ('is', 'taken'): Counter({'out': 0.0010570824524312897}),\n",
       "             ('taken', 'out'): Counter({'.': 0.003171247357293869}),\n",
       "             ('out', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'a'): Counter({'notation': 0.05122784192551635,\n",
       "                      'note': 0.05122784192551635,\n",
       "                      'comment': 0.05122784192551635,\n",
       "                      'machine': 0.05122784192551635,\n",
       "                      'theory': 0.05122784192551635,\n",
       "                      'survey': 0.05122784192551635,\n",
       "                      'history': 0.05122784192551635,\n",
       "                      'new': 0.05122784192551635,\n",
       "                      'remark': 0.05122784192551635,\n",
       "                      'primer': 0.05122784192551635}),\n",
       "             ('a', 'notation'): Counter({'for': 0.5015856236786469}),\n",
       "             ('notation', 'for'): Counter({'markov': 0.5190274841437632}),\n",
       "             ('for', 'markov'): Counter({'decision': 0.5005285412262156}),\n",
       "             ('markov',\n",
       "              'decision'): Counter({'processes': 0.5010570824524313}),\n",
       "             ('decision',\n",
       "              'processes'): Counter({';': 0.003171247357293869,\n",
       "                      '.': 0.003171247357293869}),\n",
       "             ('processes', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('paper', 'specifies'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('specifies', 'a'): Counter({'notation': 0.06659619450317125}),\n",
       "             ('processes', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'icon'): Counter({'challenge': 0.0010570824524312897}),\n",
       "             ('icon', 'challenge'): Counter({'on': 0.5015856236786469}),\n",
       "             ('challenge', 'on'): Counter({'algorithm': 0.5137420718816068}),\n",
       "             ('on', 'algorithm'): Counter({'selection': 0.5026427061310782}),\n",
       "             ('algorithm',\n",
       "              'selection'): Counter({';': 0.0021141649048625794,\n",
       "                      '.': 0.0021141649048625794}),\n",
       "             ('selection', ';'): Counter({'we': 0.02959830866807611}),\n",
       "             ('we',\n",
       "              'present'): Counter({'the': 0.003171247357293869,\n",
       "                      'our': 0.003171247357293869}),\n",
       "             ('present', 'the'): Counter({'results': 0.09936575052854123}),\n",
       "             ('the', 'results'): Counter({'of': 0.005285412262156448}),\n",
       "             ('results',\n",
       "              'of'): Counter({'the': 0.07610993657505286,\n",
       "                      'object': 0.07610993657505286}),\n",
       "             ('the', 'icon'): Counter({'challenge': 0.0010570824524312897}),\n",
       "             ('selection', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'recognition'): Counter({'of': 0.005285412262156448}),\n",
       "             ('recognition', 'of'): Counter({'regular': 0.07610993657505286}),\n",
       "             ('of', 'regular'): Counter({'shapes': 0.0010570824524312897}),\n",
       "             ('regular', 'shapes'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('shapes', 'in'): Counter({'satelite': 0.03488372093023256}),\n",
       "             ('in', 'satelite'): Counter({'images': 0.0010570824524312897}),\n",
       "             ('satelite', 'images'): Counter({';': 0.0010570824524312897}),\n",
       "             ('images',\n",
       "              ';'): Counter({'this': 0.02959830866807611,\n",
       "                      'the': 0.02959830866807611}),\n",
       "             ('author', 'ali'): Counter({'pourmohammad': 0.5005285412262156}),\n",
       "             ('ali', 'pourmohammad'): Counter({'.': 0.5005285412262156}),\n",
       "             ('pourmohammad', '.'): Counter({'_EOS_': 0.5100422832980972}),\n",
       "             ('_UNK_',\n",
       "              'glottochronologic'): Counter({'retrognostic': 0.0010570824524312897}),\n",
       "             ('glottochronologic',\n",
       "              'retrognostic'): Counter({'of': 0.5005285412262156}),\n",
       "             ('retrognostic', 'of'): Counter({'language': 0.5380549682875264}),\n",
       "             ('of', 'language'): Counter({'system': 0.5042283298097252}),\n",
       "             ('language',\n",
       "              'system'): Counter({';': 0.004228329809725159,\n",
       "                      'is': 0.004228329809725159}),\n",
       "             ('system',\n",
       "              ';'): Counter({'a': 0.02959830866807611,\n",
       "                      'we': 0.02959830866807611}),\n",
       "             ('a',\n",
       "              'glottochronologic'): Counter({'retrognostic': 0.0010570824524312897}),\n",
       "             ('system', 'is'): Counter({'proposed': 0.021141649048625793}),\n",
       "             ('is',\n",
       "              'proposed'): Counter({'_EOS_': 0.003171247357293869,\n",
       "                      '.': 0.003171247357293869}),\n",
       "             ('_UNK_',\n",
       "              'the'): Counter({'model': 0.09936575052854123,\n",
       "                      'yahoo': 0.09936575052854123,\n",
       "                      'logic': 0.09936575052854123}),\n",
       "             ('the', 'model'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('of', 'quantum'): Counter({'evolution': 0.003171247357293869}),\n",
       "             ('quantum', 'evolution'): Counter({';': 0.0010570824524312897}),\n",
       "             ('evolution', ';'): Counter({'this': 0.514799154334038}),\n",
       "             ('author', 'due'): Counter({'to': 0.7502642706131079}),\n",
       "             ('due',\n",
       "              'to'): Counter({'extremely': 0.023960535588442564,\n",
       "                      'a': 0.023960535588442564,\n",
       "                      'an': 0.023960535588442564,\n",
       "                      'some': 0.023960535588442564}),\n",
       "             ('to',\n",
       "              'extremely'): Counter({'unscientific': 0.0010570824524312897}),\n",
       "             ('extremely',\n",
       "              'unscientific'): Counter({'errors': 0.0010570824524312897}),\n",
       "             ('unscientific', 'errors'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('errors', '.'): Counter({'_EOS_': 0.5100422832980972}),\n",
       "             ('_UNK_', 'utility'): Counter({'-': 0.0021141649048625794}),\n",
       "             ('utility', '-'): Counter({'probability': 0.02748414376321353}),\n",
       "             ('-', 'probability'): Counter({'duality': 0.004228329809725159}),\n",
       "             ('probability', 'duality'): Counter({';': 0.0021141649048625794}),\n",
       "             ('duality', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('paper',\n",
       "              'presents'): Counter({'duality': 0.003171247357293869,\n",
       "                      'some': 0.003171247357293869,\n",
       "                      'an': 0.003171247357293869}),\n",
       "             ('presents',\n",
       "              'duality'): Counter({'between': 0.0021141649048625794}),\n",
       "             ('duality',\n",
       "              'between'): Counter({'probability': 0.005285412262156448}),\n",
       "             ('between',\n",
       "              'probability'): Counter({'distributions': 0.004228329809725159}),\n",
       "             ('probability',\n",
       "              'distributions'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('distributions',\n",
       "              'and'): Counter({'utility': 0.048625792811839326}),\n",
       "             ('and', 'utility'): Counter({'functions': 0.0021141649048625794}),\n",
       "             ('utility', 'functions'): Counter({'.': 0.003171247357293869}),\n",
       "             ('functions', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'temporized'): Counter({'equilibria': 0.0010570824524312897}),\n",
       "             ('temporized',\n",
       "              'equilibria'): Counter({';': 0.0010570824524312897}),\n",
       "             ('equilibria', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('to',\n",
       "              'a'): Counter({'crucial': 0.04439746300211417,\n",
       "                      'major': 0.04439746300211417}),\n",
       "             ('a',\n",
       "              'crucial'): Counter({'error': 0.0021141649048625794,\n",
       "                      'sign': 0.0021141649048625794}),\n",
       "             ('crucial', 'error'): Counter({'in': 0.0021141649048625794}),\n",
       "             ('error',\n",
       "              'in'): Counter({'the': 0.03488372093023256,\n",
       "                      'eq': 0.03488372093023256,\n",
       "                      'equation': 0.03488372093023256}),\n",
       "             ('in',\n",
       "              'the'): Counter({'submission': 0.08517064331017819,\n",
       "                      'translation': 0.08517064331017819,\n",
       "                      'future': 0.08517064331017819,\n",
       "                      'face': 0.08517064331017819,\n",
       "                      'behavior': 0.08517064331017819,\n",
       "                      'area': 0.08517064331017819}),\n",
       "             ('the', 'submission'): Counter({'action': 0.004228329809725159}),\n",
       "             ('submission', 'action'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('action', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'backpropagation'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('backpropagation',\n",
       "              'in'): Counter({'matrix': 0.03488372093023256}),\n",
       "             ('in', 'matrix'): Counter({'notation': 0.5010570824524313}),\n",
       "             ('matrix',\n",
       "              'notation'): Counter({';': 0.003171247357293869,\n",
       "                      '.': 0.003171247357293869}),\n",
       "             ('notation', ';'): Counter({'in': 0.02959830866807611}),\n",
       "             (';', 'in'): Counter({'this': 0.9034883720930232}),\n",
       "             ('in',\n",
       "              'this'): Counter({'note': 0.010782241014799153,\n",
       "                      'paper': 0.010782241014799153,\n",
       "                      'work': 0.010782241014799153,\n",
       "                      'article': 0.010782241014799153,\n",
       "                      'survey': 0.010782241014799153,\n",
       "                      'manuscript': 0.010782241014799153}),\n",
       "             ('this', 'note'): Counter({'we': 0.5015856236786469}),\n",
       "             ('note',\n",
       "              'we'): Counter({'calculate': 0.017970401691331923,\n",
       "                      'study': 0.017970401691331923}),\n",
       "             ('we', 'calculate'): Counter({'the': 0.0021141649048625794}),\n",
       "             ('calculate',\n",
       "              'the'): Counter({'gradient': 0.09936575052854123,\n",
       "                      'distance': 0.09936575052854123}),\n",
       "             ('the', 'gradient'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('gradient', 'of'): Counter({'the': 0.07610993657505286}),\n",
       "             ('the', 'network'): Counter({'function': 0.006342494714587738}),\n",
       "             ('network', 'function'): Counter({'in': 0.0021141649048625794}),\n",
       "             ('function', 'in'): Counter({'matrix': 0.03488372093023256}),\n",
       "             ('notation', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'random'): Counter({'dfas': 0.0010570824524312897}),\n",
       "             ('random', 'dfas'): Counter({'are': 0.0010570824524312897}),\n",
       "             ('dfas', 'are'): Counter({'efficiently': 0.008456659619450317}),\n",
       "             ('are', 'efficiently'): Counter({'pac': 0.0010570824524312897}),\n",
       "             ('efficiently',\n",
       "              'pac'): Counter({'learnable': 0.0010570824524312897}),\n",
       "             ('pac', 'learnable'): Counter({';': 0.0010570824524312897}),\n",
       "             ('learnable', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('withdrawn', 'due'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('to', 'an'): Counter({'error': 0.010570824524312896}),\n",
       "             ('an', 'error'): Counter({'found': 0.0021141649048625794}),\n",
       "             ('error', 'found'): Counter({'by': 0.0010570824524312897}),\n",
       "             ('found', 'by'): Counter({'dana': 0.008456659619450317}),\n",
       "             ('by', 'dana'): Counter({'angluin': 0.0010570824524312897}),\n",
       "             ('dana', 'angluin'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('angluin', 'and'): Counter({'lev': 0.048625792811839326}),\n",
       "             ('and', 'lev'): Counter({'reyzin': 0.0010570824524312897}),\n",
       "             ('lev', 'reyzin'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('reyzin', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'network'): Counter({'motifs': 0.006342494714587738}),\n",
       "             ('network', 'motifs'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('motifs', 'in'): Counter({'music': 0.03488372093023256}),\n",
       "             ('in', 'music'): Counter({'sequences': 0.003171247357293869}),\n",
       "             ('music', 'sequences'): Counter({';': 0.0010570824524312897}),\n",
       "             ('sequences', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('author', 'because'): Counter({'it': 0.0021141649048625794}),\n",
       "             ('because',\n",
       "              'it'): Counter({'needs': 0.005285412262156448,\n",
       "                      'is': 0.005285412262156448}),\n",
       "             ('it', 'needs'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('needs', 'a'): Counter({'deep': 0.06659619450317125}),\n",
       "             ('a', 'deep'): Counter({'methodological': 0.004228329809725159}),\n",
       "             ('deep',\n",
       "              'methodological'): Counter({'revision': 0.0010570824524312897}),\n",
       "             ('methodological',\n",
       "              'revision'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('revision', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'glottochronology'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('glottochronology',\n",
       "              'and'): Counter({'problems': 0.048625792811839326}),\n",
       "             ('and', 'problems'): Counter({'of': 0.003171247357293869}),\n",
       "             ('problems',\n",
       "              'of'): Counter({'protolanguage': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'protolanguage'): Counter({'reconstruction': 0.0010570824524312897}),\n",
       "             ('protolanguage',\n",
       "              'reconstruction'): Counter({';': 0.003171247357293869}),\n",
       "             ('reconstruction',\n",
       "              ';'): Counter({'a': 0.02959830866807611,\n",
       "                      'in': 0.02959830866807611}),\n",
       "             ('a',\n",
       "              'method'): Counter({'of': 0.005285412262156448,\n",
       "                      'for': 0.005285412262156448}),\n",
       "             ('method',\n",
       "              'of'): Counter({'languages': 0.07610993657505286,\n",
       "                      'using': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'languages'): Counter({'genealogical': 0.004228329809725159}),\n",
       "             ('languages',\n",
       "              'genealogical'): Counter({'trees': 0.0010570824524312897}),\n",
       "             ('genealogical',\n",
       "              'trees'): Counter({'construction': 0.0021141649048625794}),\n",
       "             ('trees', 'construction'): Counter({'is': 0.0010570824524312897}),\n",
       "             ('construction',\n",
       "              'is'): Counter({'proposed': 0.021141649048625793}),\n",
       "             ('proposed', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'using'): Counter({'slp': 0.006342494714587738,\n",
       "                      'sets': 0.006342494714587738}),\n",
       "             ('using', 'slp'): Counter({'neural': 0.0010570824524312897}),\n",
       "             ('slp', 'neural'): Counter({'network': 0.0021141649048625794}),\n",
       "             ('neural',\n",
       "              'network'): Counter({'to': 0.006342494714587738,\n",
       "                      'inspired': 0.006342494714587738,\n",
       "                      'learning': 0.006342494714587738,\n",
       "                      'building': 0.006342494714587738}),\n",
       "             ('network', 'to'): Counter({'persian': 0.035940803382663845}),\n",
       "             ('to',\n",
       "              'persian'): Counter({'handwritten': 0.0010570824524312897}),\n",
       "             ('persian',\n",
       "              'handwritten'): Counter({'digits': 0.0010570824524312897}),\n",
       "             ('handwritten',\n",
       "              'digits'): Counter({'recognition': 0.0010570824524312897}),\n",
       "             ('digits', 'recognition'): Counter({';': 0.005285412262156448}),\n",
       "             ('recognition', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('_UNK_', 'time'): Counter({'hopping': 0.003171247357293869}),\n",
       "             ('time',\n",
       "              'hopping'): Counter({'technique': 0.0010570824524312897}),\n",
       "             ('hopping', 'technique'): Counter({'for': 0.0021141649048625794}),\n",
       "             ('technique', 'for'): Counter({'faster': 0.03805496828752643}),\n",
       "             ('for',\n",
       "              'faster'): Counter({'reinforcement': 0.0010570824524312897}),\n",
       "             ('faster',\n",
       "              'reinforcement'): Counter({'learning': 0.0010570824524312897}),\n",
       "             ('reinforcement',\n",
       "              'learning'): Counter({'in': 0.011627906976744186}),\n",
       "             ('learning', 'in'): Counter({'simulations': 0.03488372093023256}),\n",
       "             ('in', 'simulations'): Counter({';': 0.0010570824524312897}),\n",
       "             ('simulations', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('this', 'preprint'): Counter({'has': 0.0010570824524312897}),\n",
       "             ('preprint', 'has'): Counter({'been': 0.0010570824524312897}),\n",
       "             ('author', 'for'): Counter({'revision': 0.03805496828752643}),\n",
       "             ('for', 'revision'): Counter({'_EOS_': 0.0021141649048625794}),\n",
       "             ('_UNK_',\n",
       "              'convolutional'): Counter({'matching': 0.0010570824524312897}),\n",
       "             ('convolutional',\n",
       "              'matching'): Counter({'pursuit': 0.0010570824524312897}),\n",
       "             ('matching', 'pursuit'): Counter({'and': 0.5005285412262156}),\n",
       "             ('pursuit',\n",
       "              'and'): Counter({'dictionary': 0.048625792811839326,\n",
       "                      'k': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'dictionary'): Counter({'training': 0.0021141649048625794}),\n",
       "             ('dictionary', 'training'): Counter({';': 0.0021141649048625794}),\n",
       "             ('training', ';'): Counter({'matching': 0.02959830866807611}),\n",
       "             (';', 'matching'): Counter({'pursuit': 0.0010570824524312897}),\n",
       "             ('and', 'k'): Counter({'-': 0.0021141649048625794}),\n",
       "             ('k', '-'): Counter({'svd': 0.02748414376321353}),\n",
       "             ('-', 'svd'): Counter({'is': 0.0010570824524312897}),\n",
       "             ('svd', 'is'): Counter({'demonstrated': 0.021141649048625793}),\n",
       "             ('is', 'demonstrated'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('demonstrated', 'in'): Counter({'the': 0.03488372093023256}),\n",
       "             ('the',\n",
       "              'translation'): Counter({'invariant': 0.0010570824524312897}),\n",
       "             ('translation',\n",
       "              'invariant'): Counter({'setting': 0.0010570824524312897}),\n",
       "             ('invariant',\n",
       "              'setting'): Counter({'_EOS_': 0.0010570824524312897}),\n",
       "             ('_UNK_',\n",
       "              'fitness'): Counter({'landscape': 0.0010570824524312897}),\n",
       "             ('fitness',\n",
       "              'landscape'): Counter({'analysis': 0.0010570824524312897}),\n",
       "             ('landscape', 'analysis'): Counter({'for': 0.004228329809725159}),\n",
       "             ('analysis',\n",
       "              'for'): Counter({'dynamic': 0.03805496828752643,\n",
       "                      'paracontracting': 0.03805496828752643}),\n",
       "             ('for', 'dynamic'): Counter({'resource': 0.0010570824524312897}),\n",
       "             ('dynamic',\n",
       "              'resource'): Counter({'allocation': 0.0010570824524312897}),\n",
       "             ('resource',\n",
       "              'allocation'): Counter({'in': 0.0021141649048625794,\n",
       "                      'of': 0.0021141649048625794}),\n",
       "             ('allocation', 'in'): Counter({'multiuser': 0.03488372093023256}),\n",
       "             ('in', 'multiuser'): Counter({'ofdm': 0.0010570824524312897}),\n",
       "             ('multiuser', 'ofdm'): Counter({'based': 0.0010570824524312897}),\n",
       "             ('ofdm', 'based'): Counter({'cognitive': 0.5026427061310782}),\n",
       "             ('based', 'cognitive'): Counter({'radio': 0.5005285412262156}),\n",
       "             ('cognitive', 'radio'): Counter({'systems': 0.5005285412262156}),\n",
       "             ('radio',\n",
       "              'systems'): Counter({';': 0.0021141649048625794,\n",
       "                      'under': 0.0021141649048625794}),\n",
       "             ('systems', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('a', 'note'): Counter({'on': 0.6677237491190979}),\n",
       "             ('note',\n",
       "              'on'): Counter({'darwiche': 0.02748414376321353,\n",
       "                      'the': 0.02748414376321353,\n",
       "                      'adjusting': 0.02748414376321353}),\n",
       "             ('on', 'darwiche'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('darwiche', 'and'): Counter({'pearl': 0.5243128964059197}),\n",
       "             ('and',\n",
       "              'pearl'): Counter({';': 0.0021141649048625794,\n",
       "                      \"'\": 0.0021141649048625794}),\n",
       "             ('pearl', ';'): Counter({'it': 0.02959830866807611}),\n",
       "             (';', 'it'): Counter({'is': 0.005285412262156448}),\n",
       "             ('it',\n",
       "              'is'): Counter({'shown': 0.021141649048625793,\n",
       "                      'complete': 0.021141649048625793,\n",
       "                      'no': 0.021141649048625793,\n",
       "                      'intentionally': 0.021141649048625793}),\n",
       "             ('shown', 'that'): Counter({'darwiche': 0.008456659619450317}),\n",
       "             ('that', 'darwiche'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('pearl', \"'\"): Counter({'s': 0.006342494714587738}),\n",
       "             (\"'\",\n",
       "              's'): Counter({'postulates': 0.003171247357293869,\n",
       "                      'assumption': 0.003171247357293869}),\n",
       "             ('s', 'postulates'): Counter({'imply': 0.0010570824524312897}),\n",
       "             ('postulates', 'imply'): Counter({'an': 0.0010570824524312897}),\n",
       "             ('imply', 'an'): Counter({'interesting': 0.010570824524312896}),\n",
       "             ('an',\n",
       "              'interesting'): Counter({'property': 0.0010570824524312897}),\n",
       "             ('interesting',\n",
       "              'property'): Counter({',': 0.0010570824524312897}),\n",
       "             ('property', ','): Counter({'not': 0.03805496828752643}),\n",
       "             (',', 'not'): Counter({'noticed': 0.008456659619450317}),\n",
       "             ('not', 'noticed'): Counter({'by': 0.0010570824524312897}),\n",
       "             ('noticed', 'by'): Counter({'the': 0.008456659619450317}),\n",
       "             ('the',\n",
       "              'authors'): Counter({'.': 0.0021141649048625794,\n",
       "                      'due': 0.0021141649048625794}),\n",
       "             ('authors', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'flip'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('flip', '-'): Counter({'flop': 0.02748414376321353}),\n",
       "             ('-', 'flop'): Counter({'sublinear': 0.0010570824524312897}),\n",
       "             ('flop', 'sublinear'): Counter({'models': 0.0010570824524312897}),\n",
       "             ('sublinear',\n",
       "              'models'): Counter({'for': 0.005285412262156448,\n",
       "                      'on': 0.005285412262156448}),\n",
       "             ('models', 'for'): Counter({'graphs': 0.03805496828752643}),\n",
       "             ('for', 'graphs'): Counter({':': 0.0021141649048625794}),\n",
       "             ('graphs', ':'): Counter({'proof': 0.009513742071881607}),\n",
       "             (':', 'proof'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('proof', 'of'): Counter({'theorem': 0.07610993657505286}),\n",
       "             ('of', 'theorem'): Counter({'1': 0.0010570824524312897}),\n",
       "             ('theorem', '1'): Counter({';': 0.004228329809725159}),\n",
       "             ('1', ';'): Counter({'we': 0.02959830866807611}),\n",
       "             ('we', 'prove'): Counter({'that': 0.0010570824524312897}),\n",
       "             ('prove', 'that'): Counter({'there': 0.008456659619450317}),\n",
       "             ('that', 'there'): Counter({'is': 0.0010570824524312897}),\n",
       "             ('there', 'is'): Counter({'no': 0.021141649048625793}),\n",
       "             ('is',\n",
       "              'no'): Counter({'class': 0.0021141649048625794,\n",
       "                      'more': 0.0021141649048625794}),\n",
       "             ('no', 'class'): Counter({'-': 0.0021141649048625794}),\n",
       "             ('class', '-'): Counter({'dual': 0.02748414376321353}),\n",
       "             ('-',\n",
       "              'dual'): Counter({'for': 0.0021141649048625794,\n",
       "                      'message': 0.0021141649048625794}),\n",
       "             ('dual', 'for'): Counter({'almost': 0.03805496828752643}),\n",
       "             ('for', 'almost'): Counter({'all': 0.0010570824524312897}),\n",
       "             ('almost', 'all'): Counter({'sublinear': 0.003171247357293869}),\n",
       "             ('all', 'sublinear'): Counter({'models': 0.0010570824524312897}),\n",
       "             ('models', 'on'): Counter({'graphs': 0.02748414376321353}),\n",
       "             ('on', 'graphs'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('graphs', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'autonomous'): Counter({'perceptron': 0.0010570824524312897}),\n",
       "             ('autonomous',\n",
       "              'perceptron'): Counter({'neural': 0.0021141649048625794}),\n",
       "             ('perceptron',\n",
       "              'neural'): Counter({'network': 0.0021141649048625794}),\n",
       "             ('network', 'inspired'): Counter({'from': 0.0010570824524312897}),\n",
       "             ('inspired', 'from'): Counter({'quantum': 0.005285412262156448}),\n",
       "             ('from', 'quantum'): Counter({'computing': 0.003171247357293869}),\n",
       "             ('quantum', 'computing'): Counter({';': 0.0021141649048625794}),\n",
       "             ('computing', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('this', 'abstract'): Counter({'will': 0.0010570824524312897}),\n",
       "             ('abstract', 'will'): Counter({'be': 0.0010570824524312897}),\n",
       "             ('be', 'modified'): Counter({'after': 0.0010570824524312897}),\n",
       "             ('modified',\n",
       "              'after'): Counter({'correcting': 0.0010570824524312897}),\n",
       "             ('after', 'correcting'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('correcting', 'the'): Counter({'minor': 0.09936575052854123}),\n",
       "             ('the', 'minor'): Counter({'error': 0.0010570824524312897}),\n",
       "             ('minor', 'error'): Counter({'in': 0.0021141649048625794}),\n",
       "             ('in', 'eq'): Counter({'.(': 0.0010570824524312897}),\n",
       "             ('eq', '.('): Counter({'2': 0.0010570824524312897}),\n",
       "             ('.(', '2'): Counter({')': 0.004228329809725159}),\n",
       "             ('2', ')'): Counter({'_EOS_': 0.006342494714587738}),\n",
       "             ('using', 'sets'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('sets', 'of'): Counter({'probability': 0.5380549682875264}),\n",
       "             ('of', 'probability'): Counter({'measures': 0.5021141649048626}),\n",
       "             ('probability',\n",
       "              'measures'): Counter({'to': 0.0021141649048625794,\n",
       "                      'as': 0.0021141649048625794}),\n",
       "             ('measures', 'to'): Counter({'represent': 0.035940803382663845}),\n",
       "             ('to',\n",
       "              'represent'): Counter({'uncertainty': 0.0010570824524312897}),\n",
       "             ('represent',\n",
       "              'uncertainty'): Counter({';': 0.0021141649048625794}),\n",
       "             ('uncertainty',\n",
       "              ';'): Counter({'i': 0.02959830866807611,\n",
       "                      'we': 0.02959830866807611}),\n",
       "             (';', 'i'): Counter({'explore': 0.0021141649048625794}),\n",
       "             ('i', 'explore'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('explore', 'the'): Counter({'use': 0.09936575052854123}),\n",
       "             ('the', 'use'): Counter({'of': 0.005285412262156448}),\n",
       "             ('use',\n",
       "              'of'): Counter({'sets': 0.07610993657505286,\n",
       "                      'the': 0.07610993657505286}),\n",
       "             ('of', 'sets'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('measures', 'as'): Counter({'a': 0.005285412262156448}),\n",
       "             ('as',\n",
       "              'a'): Counter({'representation': 0.06659619450317125,\n",
       "                      'presentation': 0.06659619450317125,\n",
       "                      'game': 0.06659619450317125}),\n",
       "             ('a', 'representation'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('representation',\n",
       "              'of'): Counter({'uncertainty': 0.07610993657505286,\n",
       "                      'its': 0.07610993657505286,\n",
       "                      'lexical': 0.07610993657505286,\n",
       "                      'sat': 0.07610993657505286}),\n",
       "             ('of', 'uncertainty'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('uncertainty', '.'): Counter({'_EOS_': 0.5100422832980972}),\n",
       "             ('a', 'comment'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('comment',\n",
       "              'on'): Counter({'argumentation': 0.35165609584214236,\n",
       "                      '\"': 0.35165609584214236}),\n",
       "             ('on', 'argumentation'): Counter({';': 0.0021141649048625794}),\n",
       "             ('argumentation', ';'): Counter({'we': 0.02959830866807611}),\n",
       "             ('we',\n",
       "              'use'): Counter({'the': 0.005285412262156448,\n",
       "                      'group': 0.005285412262156448,\n",
       "                      'marker': 0.005285412262156448}),\n",
       "             ('use', 'the'): Counter({'theory': 0.09936575052854123}),\n",
       "             ('the', 'theory'): Counter({'of': 0.003171247357293869}),\n",
       "             ('theory',\n",
       "              'of'): Counter({'defaults': 0.07610993657505286,\n",
       "                      'argumentation': 0.07610993657505286,\n",
       "                      'experiment': 0.07610993657505286}),\n",
       "             ('of', 'defaults'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('defaults', 'and'): Counter({'their': 0.048625792811839326}),\n",
       "             ('their', 'meaning'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('meaning', 'of'): Counter({'[': 0.07610993657505286}),\n",
       "             ('of', '['): Counter({'gs16': 0.003171247357293869}),\n",
       "             ('[', 'gs16'): Counter({']': 0.0010570824524312897}),\n",
       "             ('gs16', ']'): Counter({'to': 0.003171247357293869}),\n",
       "             (']', 'to'): Counter({'develop': 0.035940803382663845}),\n",
       "             ('to',\n",
       "              'develop'): Counter({'(': 0.0021141649048625794,\n",
       "                      'a': 0.0021141649048625794}),\n",
       "             ('develop', '('): Counter({'the': 0.007399577167019027}),\n",
       "             ('(', 'the'): Counter({'outline': 0.09936575052854123}),\n",
       "             ('the', 'outline'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('outline', 'of'): Counter({'a': 0.07610993657505286}),\n",
       "             ('a', ')'): Counter({'new': 0.006342494714587738}),\n",
       "             (')', 'new'): Counter({'theory': 0.007399577167019027}),\n",
       "             ('new', 'theory'): Counter({'of': 0.003171247357293869}),\n",
       "             ('of', 'argumentation'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('argumentation', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'activitynet'): Counter({'challenge': 0.0021141649048625794}),\n",
       "             ('activitynet',\n",
       "              'challenge'): Counter({'2017': 0.003171247357293869}),\n",
       "             ('challenge', '2017'): Counter({'summary': 0.5015856236786469}),\n",
       "             ('2017',\n",
       "              'summary'): Counter({';': 0.0021141649048625794,\n",
       "                      ':': 0.0021141649048625794}),\n",
       "             ('summary', ';'): Counter({'the': 0.02959830866807611}),\n",
       "             (';',\n",
       "              'the'): Counter({'activitynet': 0.09936575052854123,\n",
       "                      'author': 0.09936575052854123,\n",
       "                      'development': 0.09936575052854123,\n",
       "                      'method': 0.09936575052854123,\n",
       "                      'cornell': 0.09936575052854123,\n",
       "                      'aim': 0.09936575052854123}),\n",
       "             ('the', 'activitynet'): Counter({'large': 0.0021141649048625794}),\n",
       "             ('activitynet',\n",
       "              'large'): Counter({'scale': 0.0010570824524312897}),\n",
       "             ('large',\n",
       "              'scale'): Counter({'activity': 0.003171247357293869,\n",
       "                      'graphical': 0.003171247357293869,\n",
       "                      'structured': 0.003171247357293869}),\n",
       "             ('scale',\n",
       "              'activity'): Counter({'recognition': 0.0010570824524312897}),\n",
       "             ('activity',\n",
       "              'recognition'): Counter({'challenge': 0.005285412262156448}),\n",
       "             ('recognition',\n",
       "              'challenge'): Counter({'2017': 0.003171247357293869}),\n",
       "             ('summary', ':'): Counter({'results': 0.009513742071881607}),\n",
       "             (':', 'results'): Counter({'and': 0.005285412262156448}),\n",
       "             ('results', 'and'): Counter({'challenge': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'challenge'): Counter({'participants': 0.003171247357293869}),\n",
       "             ('challenge',\n",
       "              'participants'): Counter({'papers': 0.0010570824524312897}),\n",
       "             ('participants', 'papers'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('papers', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('the',\n",
       "              'yahoo'): Counter({'query': 0.0021141649048625794,\n",
       "                      'webscope': 0.0021141649048625794}),\n",
       "             ('yahoo', 'query'): Counter({'treebank': 0.0010570824524312897}),\n",
       "             ('query', 'treebank'): Counter({',': 0.5005285412262156}),\n",
       "             ('treebank',\n",
       "              ','): Counter({'v': 0.03805496828752643,\n",
       "                      'version': 0.03805496828752643}),\n",
       "             (',', 'v'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('v', '.'): Counter({'1': 0.0200845665961945}),\n",
       "             ('.',\n",
       "              '1'): Counter({'.': 0.004228329809725159,\n",
       "                      'will': 0.004228329809725159}),\n",
       "             ('1',\n",
       "              '.'): Counter({'0': 0.013389711064129667,\n",
       "                      '3': 0.013389711064129667}),\n",
       "             ('.',\n",
       "              '0'): Counter({';': 0.0021141649048625794,\n",
       "                      ',': 0.0021141649048625794}),\n",
       "             ('0', ';'): Counter({'a': 0.02959830866807611}),\n",
       "             ('description',\n",
       "              'and'): Counter({'annotation': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'annotation'): Counter({'guidelines': 0.0010570824524312897}),\n",
       "             ('annotation',\n",
       "              'guidelines'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('guidelines', 'for'): Counter({'the': 0.03805496828752643}),\n",
       "             ('yahoo',\n",
       "              'webscope'): Counter({'release': 0.0010570824524312897}),\n",
       "             ('webscope', 'release'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('release', 'of'): Counter({'query': 0.07610993657505286}),\n",
       "             ('of', 'query'): Counter({'treebank': 0.0010570824524312897}),\n",
       "             (',', 'version'): Counter({'1': 0.003171247357293869}),\n",
       "             ('version', '1'): Counter({'.': 0.004228329809725159}),\n",
       "             ('0', ','): Counter({'may': 0.03805496828752643}),\n",
       "             (',',\n",
       "              'may'): Counter({'2016': 0.003171247357293869,\n",
       "                      '17': 0.003171247357293869}),\n",
       "             ('may', '2016'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('2016', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'decision'): Counter({'under': 0.0021141649048625794}),\n",
       "             ('decision',\n",
       "              'under'): Counter({'uncertainty': 0.003171247357293869}),\n",
       "             ('under', 'uncertainty'): Counter({';': 0.0021141649048625794}),\n",
       "             ('we',\n",
       "              'derive'): Counter({'axiomatically': 0.0010570824524312897}),\n",
       "             ('derive',\n",
       "              'axiomatically'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('axiomatically',\n",
       "              'the'): Counter({'probability': 0.09936575052854123}),\n",
       "             ('the',\n",
       "              'probability'): Counter({'function': 0.004228329809725159}),\n",
       "             ('probability',\n",
       "              'function'): Counter({'that': 0.0021141649048625794}),\n",
       "             ('function', 'that'): Counter({'should': 0.008456659619450317}),\n",
       "             ('that', 'should'): Counter({'be': 0.0010570824524312897}),\n",
       "             ('should', 'be'): Counter({'used': 0.007399577167019027}),\n",
       "             ('be', 'used'): Counter({'to': 0.004228329809725159}),\n",
       "             ('used', 'to'): Counter({'make': 0.035940803382663845}),\n",
       "             ('to', 'make'): Counter({'decisions': 0.0010570824524312897}),\n",
       "             ('make', 'decisions'): Counter({'given': 0.0010570824524312897}),\n",
       "             ('decisions', 'given'): Counter({'any': 0.0021141649048625794}),\n",
       "             ('given', 'any'): Counter({'form': 0.0021141649048625794}),\n",
       "             ('any', 'form'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('form', 'of'): Counter({'underlying': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'underlying'): Counter({'uncertainty': 0.0010570824524312897}),\n",
       "             ('underlying',\n",
       "              'uncertainty'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('_UNK_', 'text'): Counter({'analysis': 0.0010570824524312897}),\n",
       "             ('text', 'analysis'): Counter({'tools': 0.004228329809725159}),\n",
       "             ('analysis', 'tools'): Counter({'in': 0.0021141649048625794}),\n",
       "             ('tools', 'in'): Counter({'spoken': 0.03488372093023256}),\n",
       "             ('in', 'spoken'): Counter({'language': 0.0010570824524312897}),\n",
       "             ('spoken',\n",
       "              'language'): Counter({'processing': 0.008456659619450317}),\n",
       "             ('this',\n",
       "              'submission'): Counter({'contains': 0.004228329809725159,\n",
       "                      'has': 0.004228329809725159}),\n",
       "             ('submission',\n",
       "              'contains'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('contains',\n",
       "              'the'): Counter({'postscript': 0.09936575052854123,\n",
       "                      'proofs': 0.09936575052854123}),\n",
       "             ('the', 'postscript'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('postscript', 'of'): Counter({'the': 0.07610993657505286}),\n",
       "             ('the', 'final'): Counter({'version': 0.0010570824524312897}),\n",
       "             ('final', 'version'): Counter({'of': 0.003171247357293869}),\n",
       "             ('version', 'of'): Counter({'the': 0.5380549682875264}),\n",
       "             ('the', 'slides'): Counter({'used': 0.0010570824524312897}),\n",
       "             ('slides', 'used'): Counter({'in': 0.004228329809725159}),\n",
       "             ('used', 'in'): Counter({'our': 0.03488372093023256}),\n",
       "             ('in', 'our'): Counter({'acl': 0.004228329809725159}),\n",
       "             ('our', 'acl'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('acl', '-'): Counter({'94': 0.02748414376321353}),\n",
       "             ('-', '94'): Counter({'tutorial': 0.0010570824524312897}),\n",
       "             ('94', 'tutorial'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('tutorial', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'discrimination'): Counter({'between': 0.0010570824524312897}),\n",
       "             ('discrimination',\n",
       "              'between'): Counter({'arabic': 0.005285412262156448}),\n",
       "             ('between', 'arabic'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('arabic', 'and'): Counter({'latin': 0.048625792811839326}),\n",
       "             ('and', 'latin'): Counter({'from': 0.0010570824524312897}),\n",
       "             ('latin', 'from'): Counter({'bilingual': 0.005285412262156448}),\n",
       "             ('from',\n",
       "              'bilingual'): Counter({'documents': 0.0010570824524312897}),\n",
       "             ('bilingual', 'documents'): Counter({';': 0.0010570824524312897}),\n",
       "             ('documents', ';'): Counter({'2011': 0.02959830866807611}),\n",
       "             (';', '2011'): Counter({'international': 0.0010570824524312897}),\n",
       "             ('2011',\n",
       "              'international'): Counter({'conference': 0.0021141649048625794}),\n",
       "             ('international',\n",
       "              'conference'): Counter({'on': 0.6670190274841438}),\n",
       "             ('conference',\n",
       "              'on'): Counter({'communications': 0.35165609584214236,\n",
       "                      'logic': 0.35165609584214236}),\n",
       "             ('on', 'communications'): Counter({',': 0.0010570824524312897}),\n",
       "             ('communications',\n",
       "              ','): Counter({'computing': 0.03805496828752643}),\n",
       "             (',', 'computing'): Counter({'and': 0.0021141649048625794}),\n",
       "             ('computing', 'and'): Counter({'control': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'control'): Counter({'applications': 0.003171247357293869}),\n",
       "             ('control',\n",
       "              'applications'): Counter({'(': 0.0021141649048625794}),\n",
       "             ('applications', '('): Counter({'ccca': 0.007399577167019027}),\n",
       "             ('(', 'ccca'): Counter({')': 0.0010570824524312897}),\n",
       "             ('ccca', ')'): Counter({'_EOS_': 0.006342494714587738}),\n",
       "             ('a',\n",
       "              'machine'): Counter({'-': 0.0021141649048625794,\n",
       "                      'learning': 0.0021141649048625794}),\n",
       "             ('machine', '-'): Counter({'learning': 0.02748414376321353}),\n",
       "             ('-', 'learning'): Counter({'framework': 0.011627906976744186}),\n",
       "             ('learning', 'framework'): Counter({'for': 0.003171247357293869}),\n",
       "             ('framework',\n",
       "              'for'): Counter({'design': 0.03805496828752643,\n",
       "                      'mapping': 0.03805496828752643}),\n",
       "             ('for', 'design'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('design',\n",
       "              'for'): Counter({'manufacturability': 0.03805496828752643}),\n",
       "             ('for',\n",
       "              'manufacturability'): Counter({';': 0.0010570824524312897}),\n",
       "             ('manufacturability',\n",
       "              ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('a',\n",
       "              'duplicate'): Counter({'submission': 0.0010570824524312897}),\n",
       "             ('duplicate', 'submission'): Counter({'(': 0.004228329809725159}),\n",
       "             ('submission', '('): Counter({'original': 0.007399577167019027}),\n",
       "             ('(', 'original'): Counter({'is': 0.0010570824524312897}),\n",
       "             ('original', 'is'): Counter({'arxiv': 0.021141649048625793}),\n",
       "             ('is', 'arxiv'): Counter({':': 0.0021141649048625794}),\n",
       "             ('arxiv',\n",
       "              ':'): Counter({'1612': 0.009513742071881607,\n",
       "                      '1306': 0.009513742071881607,\n",
       "                      '0711': 0.009513742071881607}),\n",
       "             (':', '1612'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('1612', '.'): Counter({'02141': 0.0200845665961945}),\n",
       "             ('.', '02141'): Counter({').': 0.0010570824524312897}),\n",
       "             ('02141', ').'): Counter({'hence': 0.0010570824524312897}),\n",
       "             (').', 'hence'): Counter({'want': 0.0010570824524312897}),\n",
       "             ('hence', 'want'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('want', 'to'): Counter({'withdraw': 0.035940803382663845}),\n",
       "             ('to', 'withdraw'): Counter({'it': 0.0010570824524312897}),\n",
       "             ('withdraw', 'it'): Counter({'_EOS_': 0.005285412262156448}),\n",
       "             ('a', 'theory'): Counter({'of': 0.003171247357293869}),\n",
       "             ('of', 'experiment'): Counter({';': 0.003171247357293869}),\n",
       "             ('experiment', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('article', 'aims'): Counter({'at': 0.0010570824524312897}),\n",
       "             ('aims', 'at'): Counter({'clarifying': 0.003171247357293869}),\n",
       "             ('at', 'clarifying'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('clarifying', 'the'): Counter({'language': 0.09936575052854123}),\n",
       "             ('the', 'language'): Counter({'and': 0.008456659619450317}),\n",
       "             ('language', 'and'): Counter({'practice': 0.048625792811839326}),\n",
       "             ('and', 'practice'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('practice', 'of'): Counter({'scientific': 0.07610993657505286}),\n",
       "             ('of',\n",
       "              'scientific'): Counter({'experiment': 0.0010570824524312897}),\n",
       "             ('scientific',\n",
       "              'experiment'): Counter({',': 0.003171247357293869}),\n",
       "             ('experiment', ','): Counter({'mainly': 0.03805496828752643}),\n",
       "             (',', 'mainly'): Counter({'by': 0.0021141649048625794}),\n",
       "             ('mainly', 'by'): Counter({'hooking': 0.008456659619450317}),\n",
       "             ('by',\n",
       "              'hooking'): Counter({'observability': 0.0010570824524312897}),\n",
       "             ('hooking',\n",
       "              'observability'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('observability',\n",
       "              'on'): Counter({'calculability': 0.02748414376321353}),\n",
       "             ('on', 'calculability'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('calculability', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'are'): Counter({'minds': 0.008456659619450317}),\n",
       "             ('are', 'minds'): Counter({'computable': 0.0021141649048625794}),\n",
       "             ('minds', 'computable'): Counter({'?': 0.0010570824524312897}),\n",
       "             ('computable', '?'): Counter({';': 0.0010570824524312897}),\n",
       "             ('this', 'essay'): Counter({'explores': 0.0021141649048625794}),\n",
       "             ('essay', 'explores'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('explores', 'the'): Counter({'limits': 0.09936575052854123}),\n",
       "             ('the', 'limits'): Counter({'of': 0.0021141649048625794}),\n",
       "             ('limits', 'of'): Counter({'turing': 0.07610993657505286}),\n",
       "             ('of', 'turing'): Counter({'machines': 0.0010570824524312897}),\n",
       "             ('turing',\n",
       "              'machines'): Counter({'concerning': 0.0021141649048625794}),\n",
       "             ('machines',\n",
       "              'concerning'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('concerning', 'the'): Counter({'modeling': 0.09936575052854123}),\n",
       "             ('the', 'modeling'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('modeling', 'of'): Counter({'minds': 0.07610993657505286}),\n",
       "             ('of', 'minds'): Counter({'and': 0.0021141649048625794}),\n",
       "             ('minds', 'and'): Counter({'suggests': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'suggests'): Counter({'alternatives': 0.0010570824524312897}),\n",
       "             ('suggests',\n",
       "              'alternatives'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('alternatives', 'to'): Counter({'go': 0.035940803382663845}),\n",
       "             ('to', 'go'): Counter({'beyond': 0.0010570824524312897}),\n",
       "             ('go', 'beyond'): Counter({'those': 0.0021141649048625794}),\n",
       "             ('beyond', 'those'): Counter({'limits': 0.0010570824524312897}),\n",
       "             ('those', 'limits'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('limits', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'extraction'): Counter({'de': 0.0010570824524312897}),\n",
       "             ('extraction',\n",
       "              'de'): Counter({'concepts': 0.0021141649048625794}),\n",
       "             ('de', 'concepts'): Counter({'sous': 0.0021141649048625794}),\n",
       "             ('concepts',\n",
       "              'sous'): Counter({'contraintes': 0.0010570824524312897}),\n",
       "             ('sous', 'contraintes'): Counter({'dans': 0.0010570824524312897}),\n",
       "             ('contraintes', 'dans'): Counter({'des': 0.0010570824524312897}),\n",
       "             ('dans', 'des'): Counter({'données': 0.0010570824524312897}),\n",
       "             ('des', 'données'): Counter({'d': 0.0010570824524312897}),\n",
       "             ('données', 'd'): Counter({\"'\": 0.0010570824524312897}),\n",
       "             ('d', \"'\"): Counter({'expression': 0.006342494714587738}),\n",
       "             (\"'\", 'expression'): Counter({'de': 0.0010570824524312897}),\n",
       "             ('expression', 'de'): Counter({'gènes': 0.0021141649048625794}),\n",
       "             ('de', 'gènes'): Counter({';': 0.0010570824524312897}),\n",
       "             ('gènes', ';'): Counter({'in': 0.02959830866807611}),\n",
       "             ('paper', ','): Counter({'we': 0.03805496828752643}),\n",
       "             (',',\n",
       "              'we'): Counter({'propose': 0.017970401691331923,\n",
       "                      'mainly': 0.017970401691331923,\n",
       "                      'briefly': 0.017970401691331923}),\n",
       "             ('we',\n",
       "              'propose'): Counter({'a': 0.0010570824524312897,\n",
       "                      'to': 0.0010570824524312897}),\n",
       "             ('propose',\n",
       "              'a'): Counter({'technique': 0.04994714587737844,\n",
       "                      'new': 0.04994714587737844,\n",
       "                      'funny': 0.04994714587737844}),\n",
       "             ('a', 'technique'): Counter({'to': 0.0021141649048625794}),\n",
       "             ('technique', 'to'): Counter({'extract': 0.035940803382663845}),\n",
       "             ('to',\n",
       "              'extract'): Counter({'constrained': 0.0010570824524312897}),\n",
       "             ('extract',\n",
       "              'constrained'): Counter({'formal': 0.0021141649048625794}),\n",
       "             ('constrained',\n",
       "              'formal'): Counter({'concepts': 0.003171247357293869}),\n",
       "             ('formal', 'concepts'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('concepts', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'comments'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('comments',\n",
       "              'on'): Counter({'\"': 0.02748414376321353,\n",
       "                      '``': 0.02748414376321353}),\n",
       "             ('on',\n",
       "              '\"'): Counter({'a': 0.33756166314305847,\n",
       "                      'approaching': 0.33756166314305847}),\n",
       "             ('\"',\n",
       "              'a'): Counter({'new': 0.06659619450317125,\n",
       "                      'sense': 0.06659619450317125,\n",
       "                      'primal': 0.06659619450317125}),\n",
       "             ('new', 'combination'): Counter({'of': 0.5005285412262156}),\n",
       "             ('combination', 'of'): Counter({'evidence': 0.5380549682875264}),\n",
       "             ('of', 'evidence'): Counter({'based': 0.5005285412262156}),\n",
       "             ('evidence', 'based'): Counter({'on': 0.5026427061310782}),\n",
       "             ('based',\n",
       "              'on'): Counter({'compromise': 0.01649048625792812,\n",
       "                      'the': 0.01649048625792812,\n",
       "                      'a': 0.01649048625792812}),\n",
       "             ('on',\n",
       "              'compromise'): Counter({'\"': 0.0021141649048625794,\n",
       "                      \"''\": 0.0021141649048625794}),\n",
       "             ('compromise', '\"'): Counter({'by': 0.006342494714587738}),\n",
       "             ('\"',\n",
       "              'by'): Counter({'k': 0.33897110641296685,\n",
       "                      'cong': 0.33897110641296685}),\n",
       "             ('by', 'k'): Counter({'.': 0.5010570824524313}),\n",
       "             ('k', '.'): Counter({'yamada': 0.5100422832980972}),\n",
       "             ('.',\n",
       "              'yamada'): Counter({';': 0.0021141649048625794,\n",
       "                      '_EOS_': 0.0021141649048625794}),\n",
       "             ('yamada', ';'): Counter({'comments': 0.02959830866807611}),\n",
       "             (';', 'comments'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('on', '``'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('``', 'a'): Counter({'new': 0.06659619450317125}),\n",
       "             ('compromise', \"''\"): Counter({'by': 0.0010570824524312897}),\n",
       "             (\"''\", 'by'): Counter({'k': 0.008456659619450317}),\n",
       "             ('_UNK_',\n",
       "              'learning'): Counter({'low': 0.011627906976744186,\n",
       "                      'states': 0.011627906976744186}),\n",
       "             ('learning', 'low'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('low', '-'): Counter({'shot': 0.02748414376321353}),\n",
       "             ('-',\n",
       "              'shot'): Counter({'facial': 0.0021141649048625794,\n",
       "                      'face': 0.0021141649048625794}),\n",
       "             ('shot',\n",
       "              'facial'): Counter({'representations': 0.0010570824524312897}),\n",
       "             ('facial',\n",
       "              'representations'): Counter({'via': 0.0021141649048625794}),\n",
       "             ('representations', 'via'): Counter({'2d': 0.003171247357293869}),\n",
       "             ('via', '2d'): Counter({'warping': 0.0010570824524312897}),\n",
       "             ('2d',\n",
       "              'warping'): Counter({';': 0.0021141649048625794,\n",
       "                      'module': 0.0021141649048625794}),\n",
       "             ('warping', ';'): Counter({'in': 0.02959830866807611}),\n",
       "             ('this',\n",
       "              'work'): Counter({',': 0.003171247357293869,\n",
       "                      'is': 0.003171247357293869}),\n",
       "             ('work', ','): Counter({'we': 0.03805496828752643}),\n",
       "             ('we', 'mainly'): Counter({'study': 0.0021141649048625794}),\n",
       "             ('mainly', 'study'): Counter({'the': 0.0021141649048625794}),\n",
       "             ('study',\n",
       "              'the'): Counter({'influence': 0.09936575052854123,\n",
       "                      'connection': 0.09936575052854123}),\n",
       "             ('the', 'influence'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('influence', 'of'): Counter({'the': 0.07610993657505286}),\n",
       "             ('the', '2d'): Counter({'warping': 0.0010570824524312897}),\n",
       "             ('warping', 'module'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('module', 'for'): Counter({'one': 0.03805496828752643}),\n",
       "             ('for', 'one'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('one',\n",
       "              '-'): Counter({'shot': 0.02748414376321353,\n",
       "                      'out': 0.02748414376321353}),\n",
       "             ('shot', 'face'): Counter({'recognition': 0.0021141649048625794}),\n",
       "             ('face', 'recognition'): Counter({'.': 0.005285412262156448}),\n",
       "             ('recognition', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'automatic'): Counter({'generation': 0.003171247357293869,\n",
       "                      'liver': 0.003171247357293869}),\n",
       "             ('automatic',\n",
       "              'generation'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('generation',\n",
       "              'of'): Counter({'benchmarks': 0.07610993657505286}),\n",
       "             ('of', 'benchmarks'): Counter({'for': 0.0010570824524312897}),\n",
       "             ('benchmarks',\n",
       "              'for'): Counter({'plagiarism': 0.03805496828752643}),\n",
       "             ('for',\n",
       "              'plagiarism'): Counter({'detection': 0.0010570824524312897}),\n",
       "             ('plagiarism',\n",
       "              'detection'): Counter({'tools': 0.0021141649048625794}),\n",
       "             ('detection', 'tools'): Counter({'using': 0.0021141649048625794}),\n",
       "             ('tools',\n",
       "              'using'): Counter({'grammatical': 0.006342494714587738}),\n",
       "             ('using',\n",
       "              'grammatical'): Counter({'evolution': 0.0010570824524312897}),\n",
       "             ('grammatical',\n",
       "              'evolution'): Counter({';': 0.0010570824524312897}),\n",
       "             ('authors', 'due'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('a', 'major'): Counter({'rewriting': 0.0021141649048625794}),\n",
       "             ('major', 'rewriting'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('rewriting', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'resource'): Counter({'allocation': 0.0010570824524312897}),\n",
       "             ('allocation', 'of'): Counter({'mu': 0.07610993657505286}),\n",
       "             ('of', 'mu'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('mu', '-'): Counter({'ofdm': 0.02748414376321353}),\n",
       "             ('-', 'ofdm'): Counter({'based': 0.0010570824524312897}),\n",
       "             ('systems', 'under'): Counter({'partial': 0.003171247357293869}),\n",
       "             ('under', 'partial'): Counter({'channel': 0.0021141649048625794}),\n",
       "             ('partial', 'channel'): Counter({'state': 0.0010570824524312897}),\n",
       "             ('channel',\n",
       "              'state'): Counter({'information': 0.003171247357293869}),\n",
       "             ('state', 'information'): Counter({';': 0.003171247357293869}),\n",
       "             ('information', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('to', 'some'): Counter({'errors': 0.004228329809725159}),\n",
       "             ('some', 'errors'): Counter({'.': 0.0010570824524312897}),\n",
       "             ('_UNK_', 'advances'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('advances', 'in'): Counter({'artificial': 0.5174418604651163}),\n",
       "             ('in',\n",
       "              'artificial'): Counter({'intelligence': 0.5015856236786469}),\n",
       "             ('artificial',\n",
       "              'intelligence'): Counter({'require': 0.002114164904862579,\n",
       "                      ';': 0.002114164904862579}),\n",
       "             ('intelligence',\n",
       "              'require'): Counter({'progress': 0.5005285412262156}),\n",
       "             ('require', 'progress'): Counter({'across': 0.5005285412262156}),\n",
       "             ('progress', 'across'): Counter({'all': 0.5005285412262156}),\n",
       "             ('across', 'all'): Counter({'of': 0.5015856236786469}),\n",
       "             ('all', 'of'): Counter({'computer': 0.5380549682875264}),\n",
       "             ('of', 'computer'): Counter({'science': 0.5021141649048626}),\n",
       "             ('computer',\n",
       "              'science'): Counter({';': 0.003171247357293869,\n",
       "                      '.': 0.003171247357293869,\n",
       "                      'and': 0.003171247357293869}),\n",
       "             ('science', ';'): Counter({'advances': 0.02959830866807611}),\n",
       "             (';', 'advances'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('science', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'exploration'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('exploration', 'of'): Counter({'object': 0.07610993657505286}),\n",
       "             ('of', 'object'): Counter({'recognition': 0.5010570824524313}),\n",
       "             ('object', 'recognition'): Counter({'from': 0.5026427061310782}),\n",
       "             ('recognition', 'from'): Counter({'3d': 0.5026427061310782}),\n",
       "             ('from', '3d'): Counter({'point': 0.5005285412262156}),\n",
       "             ('3d', 'point'): Counter({'cloud': 0.5005285412262156}),\n",
       "             ('point',\n",
       "              'cloud'): Counter({';': 0.0021141649048625794,\n",
       "                      'data': 0.0021141649048625794}),\n",
       "             ('cloud', ';'): Counter({'we': 0.02959830866807611}),\n",
       "             ('present', 'our'): Counter({'latest': 0.004228329809725159}),\n",
       "             ('our', 'latest'): Counter({'experiment': 0.0010570824524312897}),\n",
       "             ('latest',\n",
       "              'experiment'): Counter({'results': 0.003171247357293869}),\n",
       "             ('experiment', 'results'): Counter({'of': 0.005285412262156448}),\n",
       "             ('cloud', 'data'): Counter({'collected': 0.004228329809725159}),\n",
       "             ('data',\n",
       "              'collected'): Counter({'through': 0.0010570824524312897}),\n",
       "             ('collected',\n",
       "              'through'): Counter({'moving': 0.0010570824524312897}),\n",
       "             ('through', 'moving'): Counter({'car': 0.0010570824524312897}),\n",
       "             ('moving', 'car'): Counter({'.': 0.0021141649048625794}),\n",
       "             ('car', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_',\n",
       "              'quantified'): Counter({'conditional': 0.0010570824524312897}),\n",
       "             ('quantified',\n",
       "              'conditional'): Counter({'logics': 0.0021141649048625794,\n",
       "                      'logic': 0.0021141649048625794}),\n",
       "             ('conditional',\n",
       "              'logics'): Counter({'are': 0.0010570824524312897}),\n",
       "             ('logics', 'are'): Counter({'fragments': 0.008456659619450317}),\n",
       "             ('are', 'fragments'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('fragments', 'of'): Counter({'hol': 0.07610993657505286}),\n",
       "             ('of', 'hol'): Counter({';': 0.0010570824524312897}),\n",
       "             ('hol', ';'): Counter({'a': 0.02959830866807611}),\n",
       "             ('a', 'semantic'): Counter({'embedding': 0.0021141649048625794}),\n",
       "             ('semantic', 'embedding'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('embedding', 'of'): Counter({'(': 0.07610993657505286}),\n",
       "             ('of', '('): Counter({'constant': 0.007399577167019027}),\n",
       "             ('(', 'constant'): Counter({'domain': 0.0010570824524312897}),\n",
       "             ('constant', 'domain'): Counter({')': 0.0010570824524312897}),\n",
       "             ('domain', ')'): Counter({'quantified': 0.006342494714587738}),\n",
       "             (')',\n",
       "              'quantified'): Counter({'conditional': 0.0010570824524312897}),\n",
       "             ('conditional', 'logic'): Counter({'in': 0.005285412262156448}),\n",
       "             ('logic', 'in'): Counter({'classical': 0.03488372093023256}),\n",
       "             ('in', 'classical'): Counter({'higher': 0.0010570824524312897}),\n",
       "             ('classical', 'higher'): Counter({'-': 0.0021141649048625794}),\n",
       "             ('higher', '-'): Counter({'order': 0.02748414376321353}),\n",
       "             ('-', 'order'): Counter({'logic': 0.0021141649048625794}),\n",
       "             ('order', 'logic'): Counter({'is': 0.005285412262156448}),\n",
       "             ('logic', 'is'): Counter({'presented': 0.021141649048625793}),\n",
       "             ('is',\n",
       "              'presented'): Counter({'.': 0.0021141649048625794,\n",
       "                      'as': 0.0021141649048625794}),\n",
       "             ('presented', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'in'): Counter({'memoriam': 0.03488372093023256}),\n",
       "             ('in', 'memoriam'): Counter({'maurice': 0.0010570824524312897}),\n",
       "             ('memoriam',\n",
       "              'maurice'): Counter({'gross': 0.0010570824524312897}),\n",
       "             ('maurice',\n",
       "              'gross'): Counter({';': 0.0021141649048625794,\n",
       "                      '(': 0.0021141649048625794}),\n",
       "             ('gross', ';'): Counter({'maurice': 0.02959830866807611}),\n",
       "             (';', 'maurice'): Counter({'gross': 0.0010570824524312897}),\n",
       "             ('gross', '('): Counter({'1934': 0.007399577167019027}),\n",
       "             ('(', '1934'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('1934', '-'): Counter({'2001': 0.02748414376321353}),\n",
       "             ('-', '2001'): Counter({')': 0.0010570824524312897}),\n",
       "             ('2001', ')'): Counter({'was': 0.006342494714587738}),\n",
       "             (')', 'was'): Counter({'both': 0.0021141649048625794}),\n",
       "             ('was', 'both'): Counter({'a': 0.0010570824524312897}),\n",
       "             ('both', 'a'): Counter({'great': 0.06659619450317125}),\n",
       "             ('a', 'great'): Counter({'linguist': 0.0010570824524312897}),\n",
       "             ('great', 'linguist'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('linguist', 'and'): Counter({'a': 0.048625792811839326}),\n",
       "             ('and', 'a'): Counter({'pioneer': 0.06659619450317125}),\n",
       "             ('a', 'pioneer'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('pioneer', 'in'): Counter({'natural': 0.03488372093023256}),\n",
       "             ('in', 'natural'): Counter({'language': 0.0010570824524312897}),\n",
       "             ('processing', '.'): Counter({'this': 0.0200845665961945}),\n",
       "             ('.', 'this'): Counter({'article': 0.017970401691331923}),\n",
       "             ('is', 'written'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('written', 'in'): Counter({'homage': 0.03488372093023256}),\n",
       "             ('in', 'homage'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('homage', 'to'): Counter({'his': 0.035940803382663845}),\n",
       "             ('to', 'his'): Counter({'memory': 0.0010570824524312897}),\n",
       "             ('his', 'memory'): Counter({'_EOS_': 0.0010570824524312897}),\n",
       "             ('_UNK_', 'introduction'): Counter({'to': 0.0021141649048625794}),\n",
       "             ('the', '26th'): Counter({'international': 0.5005285412262156}),\n",
       "             ('26th',\n",
       "              'international'): Counter({'conference': 0.5010570824524313}),\n",
       "             ('on', 'logic'): Counter({'programming': 0.6684284707540521}),\n",
       "             ('logic',\n",
       "              'programming'): Counter({'special': 0.006765327695560254,\n",
       "                      'paradigm': 0.006765327695560254,\n",
       "                      'and': 0.006765327695560254,\n",
       "                      'classes': 0.006765327695560254}),\n",
       "             ('programming',\n",
       "              'special'): Counter({'issue': 0.5005285412262156}),\n",
       "             ('issue', ';'): Counter({'this': 0.02959830866807611}),\n",
       "             ('is',\n",
       "              'the'): Counter({'preface': 0.09936575052854123,\n",
       "                      'act': 0.09936575052854123,\n",
       "                      'proceedings': 0.09936575052854123}),\n",
       "             ('the', 'preface'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('preface', 'to'): Counter({'the': 0.035940803382663845}),\n",
       "             ('_UNK_',\n",
       "              'beyond'): Counter({'description': 0.0021141649048625794}),\n",
       "             ('beyond', 'description'): Counter({'.': 0.005285412262156448}),\n",
       "             ('description', '.'): Counter({'comment': 0.0200845665961945}),\n",
       "             ('.', 'comment'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('\"', 'approaching'): Counter({'human': 0.5005285412262156}),\n",
       "             ('approaching',\n",
       "              'human'): Counter({'language': 0.5010570824524313}),\n",
       "             ('human',\n",
       "              'language'): Counter({'with': 0.005637773079633545,\n",
       "                      'in': 0.005637773079633545}),\n",
       "             ('language', 'with'): Counter({'complex': 0.5047568710359408}),\n",
       "             ('with', 'complex'): Counter({'networks': 0.5005285412262156}),\n",
       "             ('networks', '\"'): Counter({'by': 0.5031712473572939}),\n",
       "             ('by', 'cong'): Counter({'&': 0.5005285412262156}),\n",
       "             ('cong', '&'): Counter({'liu': 0.5005285412262156}),\n",
       "             ('&',\n",
       "              'liu'): Counter({';': 0.0021141649048625794,\n",
       "                      '_EOS_': 0.0021141649048625794}),\n",
       "             ('liu', ';'): Counter({'comment': 0.02959830866807611}),\n",
       "             (';', 'comment'): Counter({'on': 0.0010570824524312897}),\n",
       "             ('_UNK_', 'norm'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('norm',\n",
       "              '-'): Counter({'based': 0.02748414376321353,\n",
       "                      'constrained': 0.02748414376321353}),\n",
       "             ('-',\n",
       "              'based'): Counter({'capacity': 0.005285412262156448,\n",
       "                      'convergence': 0.005285412262156448}),\n",
       "             ('based',\n",
       "              'capacity'): Counter({'control': 0.0021141649048625794}),\n",
       "             ('capacity', 'control'): Counter({'in': 0.003171247357293869}),\n",
       "             ('control', 'in'): Counter({'neural': 0.03488372093023256}),\n",
       "             ('in', 'neural'): Counter({'networks': 0.0021141649048625794}),\n",
       "             ('we', 'investigate'): Counter({'the': 0.5005285412262156}),\n",
       "             ('investigate',\n",
       "              'the'): Counter({'capacity': 0.09936575052854123,\n",
       "                      'grapheme': 0.09936575052854123}),\n",
       "             ('the', 'capacity'): Counter({',': 0.0021141649048625794}),\n",
       "             ('capacity', ','): Counter({'convexity': 0.03805496828752643}),\n",
       "             (',', 'convexity'): Counter({'and': 0.0010570824524312897}),\n",
       "             ('convexity',\n",
       "              'and'): Counter({'characterization': 0.048625792811839326}),\n",
       "             ('and',\n",
       "              'characterization'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('characterization', 'of'): Counter({'a': 0.07610993657505286}),\n",
       "             ('a',\n",
       "              'general'): Counter({'family': 0.003171247357293869,\n",
       "                      'class': 0.003171247357293869}),\n",
       "             ('general', 'family'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('family', 'of'): Counter({'norm': 0.07610993657505286}),\n",
       "             ('of', 'norm'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('-', 'constrained'): Counter({'feed': 0.0021141649048625794}),\n",
       "             ('constrained', 'feed'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('feed', '-'): Counter({'forward': 0.02748414376321353}),\n",
       "             ('-', 'forward'): Counter({'networks': 0.0010570824524312897}),\n",
       "             ('forward', 'networks'): Counter({'.': 0.008456659619450317}),\n",
       "             ('networks', '.'): Counter({'_EOS_': 0.6733615221987315}),\n",
       "             ('_UNK_',\n",
       "              'about'): Counter({'compression': 0.003171247357293869}),\n",
       "             ('about', 'compression'): Counter({'of': 0.0010570824524312897}),\n",
       "             ('compression',\n",
       "              'of'): Counter({'vocabulary': 0.07610993657505286}),\n",
       "             ('of', 'vocabulary'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('vocabulary', 'in'): Counter({'computer': 0.03488372093023256}),\n",
       "             ('in',\n",
       "              'computer'): Counter({'oriented': 0.004228329809725159,\n",
       "                      '-': 0.004228329809725159,\n",
       "                      'science': 0.004228329809725159}),\n",
       "             ('computer',\n",
       "              'oriented'): Counter({'languages': 0.0010570824524312897}),\n",
       "             ('oriented',\n",
       "              'languages'): Counter({';': 0.004228329809725159,\n",
       "                      '.': 0.004228329809725159}),\n",
       "             ('languages', ';'): Counter({'the': 0.02959830866807611}),\n",
       "             ('author', 'uses'): Counter({'the': 0.0010570824524312897}),\n",
       "             ('uses', 'the'): Counter({'entropy': 0.09936575052854123}),\n",
       "             ('the', 'entropy'): Counter({'of': 0.5010570824524313}),\n",
       "             ('entropy',\n",
       "              'of'): Counter({'the': 0.0507399577167019,\n",
       "                      'telugu': 0.0507399577167019}),\n",
       "             ('the', 'ideal'): Counter({'bose': 0.0010570824524312897}),\n",
       "             ('ideal', 'bose'): Counter({'-': 0.0010570824524312897}),\n",
       "             ('bose', '-'): Counter({'einstein': 0.02748414376321353}),\n",
       "             ('-', 'einstein'): Counter({'gas': 0.0010570824524312897}),\n",
       "             ('einstein', 'gas'): Counter({'to': 0.0010570824524312897}),\n",
       "             ('gas', 'to'): Counter({'minimize': 0.035940803382663845}),\n",
       "             ('to', 'minimize'): Counter({'losses': 0.0010570824524312897}),\n",
       "             ('minimize', 'losses'): Counter({'in': 0.0010570824524312897}),\n",
       "             ('losses', 'in'): Counter({'computer': 0.03488372093023256}),\n",
       "             ('computer', '-'): Counter({'oriented': 0.02748414376321353}),\n",
       "             ('-', 'oriented'): Counter({'languages': 0.0010570824524312897}),\n",
       "             ('languages', '.'): Counter({'_EOS_': 0.0200845665961945}),\n",
       "             ('_UNK_', 'unary'): Counter({'coding': 0.0010570824524312897}),\n",
       "             ('unary',\n",
       "              'coding'): Counter({'for': 0.0021141649048625794,\n",
       "                      'of': 0.0021141649048625794}),\n",
       "             ('coding', 'for'): Counter({'neural': 0.03805496828752643}),\n",
       "             ('for', 'neural'): Counter({'network': 0.0021141649048625794}),\n",
       "             ('network', 'learning'): Counter({';': 0.011627906976744186}),\n",
       "             ('learning', ';'): Counter({'this': 0.514799154334038}),\n",
       "             ('presents',\n",
       "              'some'): Counter({'properties': 0.004228329809725159}),\n",
       "             ('some', 'properties'): Counter({'of': 0.6670190274841438}),\n",
       "             ('properties',\n",
       "              'of'): Counter({'unary': 0.38407329105003524,\n",
       "                      'the': 0.38407329105003524}),\n",
       "             ('of', 'unary'): Counter({'coding': 0.0010570824524312897}),\n",
       "             ('coding', 'of'): Counter({'significance': 0.07610993657505286}),\n",
       "             ('of', 'significance'): Counter({'for': 0.0010570824524312897}),\n",
       "             ...})"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lm = KneserNeyLanguageModel(dummy_lines, n=3)\n",
    "dummy_lm.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lsk91832qbmdt7x1q0a8z4"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = KneserNeyLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pp3jtkk9annp1qkou58x1b"
   },
   "outputs": [],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n, smoothing=<...>)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
